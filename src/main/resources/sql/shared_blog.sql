/*
Navicat MySQL Data Transfer

Source Server         : mysqlTest
Source Server Version : 50640
Source Host           : localhost:3306
Source Database       : shared_blog

Target Server Type    : MYSQL
Target Server Version : 50640
File Encoding         : 65001

Date: 2019-01-17 09:21:29
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for t_attach
-- ----------------------------
DROP TABLE IF EXISTS `t_attach`;
CREATE TABLE `t_attach` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `fname` varchar(100) NOT NULL DEFAULT '',
  `ftype` varchar(50) DEFAULT '',
  `fkey` varchar(100) NOT NULL DEFAULT '',
  `author_id` int(10) DEFAULT NULL,
  `created` int(10) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_attach
-- ----------------------------
INSERT INTO `t_attach` VALUES ('1', '1.png', 'image', '/upload/2019/01/s1aqc3tn7kitkp5mvog058epn5.png', '1', '1546940741');
INSERT INTO `t_attach` VALUES ('2', '2.png', 'image', '/upload/2019/01/tagc3q2bk0g48o5i7kuhuic6s6.png', '1', '1546940829');
INSERT INTO `t_attach` VALUES ('4', '4.png', 'image', '/upload/2019/01/0j6kna4j5qhr7qk51ql0ua76e6.png', '1', '1546940829');
INSERT INTO `t_attach` VALUES ('5', '3.png', 'image', '/upload/2019/01/0j53t1omrggqtos0t5sbrqikgd.png', '1', '1546940829');
INSERT INTO `t_attach` VALUES ('6', '6.png', 'image', '/upload/2019/01/0b4vpukhvqjnpp2l9td75oled0.png', '1', '1546940829');
INSERT INTO `t_attach` VALUES ('7', '5.png', 'image', '/upload/2019/01/o4htt363c0ittre33opecjclss.png', '1', '1546940829');
INSERT INTO `t_attach` VALUES ('8', '7.png', 'image', '/upload/2019/01/0fieq628dghe0p4gnslj37lndo.png', '1', '1546940829');

-- ----------------------------
-- Table structure for t_comments
-- ----------------------------
DROP TABLE IF EXISTS `t_comments`;
CREATE TABLE `t_comments` (
  `coid` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `cid` int(10) unsigned DEFAULT '0',
  `created` int(10) unsigned DEFAULT '0',
  `author` varchar(200) DEFAULT NULL,
  `author_id` int(10) unsigned DEFAULT '0',
  `owner_id` int(10) unsigned DEFAULT '0',
  `mail` varchar(200) DEFAULT NULL,
  `url` varchar(200) DEFAULT NULL,
  `ip` varchar(64) DEFAULT NULL,
  `agent` varchar(200) DEFAULT NULL,
  `content` text,
  `type` varchar(16) DEFAULT 'comment',
  `status` varchar(16) DEFAULT 'approved',
  `parent` int(10) unsigned DEFAULT '0',
  PRIMARY KEY (`coid`),
  KEY `cid` (`cid`),
  KEY `created` (`created`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_comments
-- ----------------------------
INSERT INTO `t_comments` VALUES ('2', '11', '1547003627', 'caolihui', '0', '1', '972152412@qq.com', 'http://www.csdn.net:80', '127.0.0.1', null, '感觉受益匪浅啊，谢谢博主', 'comment', 'approved', '0');
INSERT INTO `t_comments` VALUES ('3', '8', '1547178081', 'caolihui', '0', '1', '972152412@qq.com', 'https://www.baidu.com/', '127.0.0.1', null, '我会发送邮件了，啦啦啦！', 'comment', 'not_audit', '0');

-- ----------------------------
-- Table structure for t_contents
-- ----------------------------
DROP TABLE IF EXISTS `t_contents`;
CREATE TABLE `t_contents` (
  `cid` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `title` varchar(200) DEFAULT NULL,
  `slug` varchar(200) DEFAULT NULL,
  `created` int(10) unsigned DEFAULT '0',
  `modified` int(10) unsigned DEFAULT '0',
  `content` text COMMENT '内容文字',
  `author_id` int(10) unsigned DEFAULT '0',
  `type` varchar(16) DEFAULT 'post',
  `status` varchar(16) DEFAULT 'publish',
  `tags` varchar(200) DEFAULT NULL,
  `categories` varchar(200) DEFAULT NULL,
  `thumbImg` varchar(512) DEFAULT NULL,
  `hits` int(10) unsigned DEFAULT '0',
  `comments_num` int(10) unsigned DEFAULT '0',
  `allow_comment` tinyint(1) DEFAULT '1',
  `allow_ping` tinyint(1) DEFAULT '1',
  `allow_feed` tinyint(1) DEFAULT '1',
  PRIMARY KEY (`cid`),
  UNIQUE KEY `slug` (`slug`),
  KEY `created` (`created`)
) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_contents
-- ----------------------------
INSERT INTO `t_contents` VALUES ('1', 'springboot之从零开始开发自己的博客系统', 'article1', '1546849598', '1546997946', 'springboot之从零开始开发自己的博客系统\r\n发布于 2018-05-09\r\n概述\r\n首先要感谢两位大神，该项目的想法来源自tale和MyBlog，本项目的想法。\r\n\r\n做了一些改造，增加了一些功能和一些代码的重构，并且更换了博客主题。\r\n\r\n关于项目，对于开发的练手项目，能够工程化，严谨一些。\r\n\r\n关于文档，本文主要中从项目需求，项目设计的方式来阐述.\r\n\r\n如何从零开始，使用springboot开发项目。\r\n\r\n记录一些在开发过程中遇到的一些问题，总结开发技巧\r\n\r\n接下来，会以需求和设计方式来阐述\r\n\r\n效果图\r\n首页展示 ![alt](/upload/2019/01/s1aqc3tn7kitkp5mvog058epn5.png)\r\n\r\n文章编辑 ![alt](/upload/2019/01/tagc3q2bk0g48o5i7kuhuic6s6.png)\r\n\r\n文章管理 ![alt](/upload/2019/01/0j53t1omrggqtos0t5sbrqikgd.png)\r\n\r\n项目需求\r\n项目背景\r\n对于刚学习springboot的同学，最好的就是拿一个项目练练手。在编码过程中遇到的问题并解决，这都是宝贵的经验。 用springboot开发的博客系统，简单而且实用，适合做练手项目。\r\n\r\n功能需求\r\n界面需求\r\n主页\r\n博客汇总，以列表加图片的形式展示\r\n能够以分类的方式查看文章\r\n能够以时间列表的方式归档文章\r\n个人介绍，github地址\r\n搜索框，能够搜索文章\r\n后台管理\r\n管理主页，记录最新文章，最新留言，最近日志等\r\n\r\n最近日志记录登录IP，地址，操作等\r\n记录一天的访问量\r\n发布文章\r\n\r\n使用markdown编辑器，支持插入代码，插入图片等功能\r\n能够给文章添加缩略图。\r\n可将文章存为草稿或者发布\r\n文章可选择分类和标签，自定义url\r\n文章可控制是否允许评论\r\n文章管理\r\n\r\n以列表形式展示文章信息\r\n在可选操作中增加删除，预览，编辑功能\r\n支持分页显示\r\n增加搜索功能，可根据文章名文章信息\r\n分类管理\r\n\r\n可以新增、删除、修改分类\r\n文件管理\r\n\r\n支持文件上传\r\n支持删除已上传的文件\r\n友情链接\r\n\r\n支持增加友情链接\r\n支持删除友情链接\r\n系统设置\r\n\r\n支持修改密码\r\n支持备份数据库\r\n支持黑名单配置\r\n非界面需求\r\n日志记录，记录来访IP名单\r\n每天定时备份数据库\r\n安装部署需求\r\n可以使用docker方式部署，也可支持-jar方式\r\n使用springboot自带方式打包\r\n非功能性需求\r\n性能需求\r\n首页响应的时间不超过1秒钟\r\n文章页响应时间不超过1秒钟\r\n项目设计\r\n总体设计\r\n- 本项目用到的技术和框架\r\n - 项目构建： maven\r\n - web框架：spring boot\r\n - 数据库ORM：mybatis\r\n - 数据库连接池：Druid\r\n - 分页插件：PageHelper\r\n - 数据库：mysql\r\n - 缓存NOSQL：redis\r\n - 前段模板：thymeleaf\r\n - 文章展示：使用commonmark，将markdown转成html页面\r\n\r\n- 本项目的关键点\r\n - 采用springboot开发，数据库使用连接池加orm框架的模式，对于系统的关键业务使用redis缓存，加快响应速度\r\n - 整体系统采用门户网站+后台管理的方式搭建，门户主要展示博客内容，后台管理主要用于编辑文章，上传附件，控制黑名单登录等。\r\n- 环境\r\n\r\n工具| 名称\r\n------- | -------   \r\n开发工具| IDEA\r\n语言| JDK1.8, JS, HTML   \r\n数据库| mysql5.6\r\n缓存NOSQL | redis\r\n项目构建 | Maven\r\n运行环境 | 阿里云Centos7\r\n结构设计\r\n![alt](/upload/2019/01/0j6kna4j5qhr7qk51ql0ua76e6.png) 熟悉spring开发的同学，相信对此结构图也并不陌生。平时的开发过程中，结构设计是重要的缓解，特别是协作开发的时候，明细的分包，模块化，可减少在git提交时的冲突。\r\n\r\n业务设计\r\n本模块主要介绍一些关键的业务流程。\r\n\r\n发布文章流程： ![alt](/upload/2019/01/o4htt363c0ittre33opecjclss.png)\r\n\r\n修改文章的流程大致上和发布是相似的，这里不再赘述了\r\n\r\n登录流程 ![alt](/upload/2019/01/0b4vpukhvqjnpp2l9td75oled0.png)\r\n\r\n文件上传\r\n\r\n在写文章的时候，通常会使用到图片，可以引用一些网络上的图片，更好的是本系统支持上传文件和图片\r\n将文件区别为图片和其他，图片支持预览模式\r\n文件路径设计成绝对路径，在web系统中可直接引用\r\n文件按月份归类，文件名以uuid的重新命名存储\r\n其他文件支持下载\r\n文件上传流程图\r\n![alt](/upload/2019/01/0fieq628dghe0p4gnslj37lndo.png)\r\n\r\n首页展示\r\n首页也文章列表+图片的形式展示内容，默认最大显示12篇文章，包括发布时间和分类\r\n上部展示菜单栏，支持搜索，归档页等功能\r\n右侧显示菜单栏，展示个人github地址，个人信息，标签云等\r\n使用redis缓存首页的html页面，加速访问。\r\n打包、部署和运行\r\n本项目采用springboot的maven插件进行打包，打成jar形式\r\n部署方式：使用**nohub java -jar xxx.jar &**的方式，启动项目\r\n数据设计\r\n用户表：t_users\r\n\r\n名称	类型	长度	主键	非空	描述\r\nuid	int	10	true	true	主键，自增\r\nusername	varchar	32	false	false	用户名\r\npassword	varchar	64	false	false	密码\r\nemail	varchar	200	false	false	邮件地址\r\ncreted	int	10	false	false	创建时间\r\n用户表主要管理后台管理用户。\r\n\r\n文章表：t_contents\r\n\r\n名称	类型	长度	主键	非空	描述\r\ncid	int	10	true	true	主键,自增\r\ntitle	varchar	200	false	false	文章标题\r\nslug	varchar	200	false	false	url地址\r\ncreted	int	10	false	false	创建时间\r\nmodified	int	10	false	false	修改时间\r\ncontent	text	无限制	false	false	文章内容\r\nauthor_id	int	10	false	false	作者ID\r\ntype	varchar	16	false	false	文章类型\r\nstatus	varchar	16	false	false	文章状态\r\ncategories	varchar	200	false	false	分类\r\nthumbImg	varchar	512	false	false	缩略图地址\r\nhits	int	10	false	false	文章点击量\r\ncomments_num	int	10	false	false	评论数量\r\nallow_comment	int	1	false	false	允许评论\r\n主要管理文章内容，外键为cid\r\n\r\n标签表：t_metas\r\n\r\n名称	类型	长度	主键	非空	描述\r\nmid	int	10	true	true	主键，自增\r\nname	varchar	200	false	false	名称\r\nslug	varchar	200	false	false	说明\r\ntype	varchar	200	false	false	类型\r\ndescription	varchar	200	false	false	描述\r\nsort	int	10	false	false	排序\r\nparent	int	10	false	false	父标签\r\n管理标签信息，外键为mid\r\n\r\n文章标签关系表：t_relationships\r\n\r\n名称	类型	长度	主键	非空	描述\r\ncid	int	10	false	false	组合主键，用户ID\r\nuid	int	10	false	false	组合主键，标签ID\r\n记录文章和分类的关系，多对多表\r\n\r\n性能与可靠性\r\n性能设计\r\n将文章内容写入redis中，加快访问速度\r\n可靠性设计\r\n后台管理，可以系统日志，查看系统运行状态\r\n定时发送邮件，发送服务端的可用内存，cpu，最新日志，硬盘情况进行监控\r\n对于恶意的IP，支持黑名单设置，禁止访问\r\n开发流程\r\n数据库的curd\r\n首先，编写sql语句，创建数据库。\r\n\r\n本项目的crud操作采用mybatis的逆向功能，对于特殊操作，需要自己手写sql语句\r\n\r\nspringboot如何使用mybatis，以及mybatis的逆向工程，请参考springboot与mybatis\r\n\r\n编写service层，根据需求分析和概要设计，将具体业务转成具体代码\r\n\r\n关于事务的使用，使用srping中的@Transactional，还是很方便的\r\n\r\n本流程的开发不是特别难，关键在于业务的实现\r\n\r\n页面与展示\r\n作为一个后端开发，css的功力还是有所欠缺的，所以也是用了妹子UI主题，和tale的后端页面，大大减少了页面的开发难度，特此感谢\r\n\r\n页面与后端的交换主要是在controller包中，springboot的页面开发和springmvc是几乎一样的，@PostMapping和@GetMapping这两个注解也是方便了开发。\r\n\r\n统一的异常处理，使用@ControllerAdvice，定义异常页面，设置自动跳转500，404页面。\r\n\r\n拦截器，获取http请求中的ip，判断是否在黑名单（如果在，则禁止访问系统）\r\n\r\n其他功能\r\n该项目是在My blog基础上修改的，修复了部分bug，增加添加黑白单功能，指定文章缩略图\r\n\r\n分析访问量最多的数据，主要在于文章访问部分，将文章放入redis缓存。每次编辑完文章后，更新缓存\r\n\r\n每天定时发送邮件，汇报服务器运行状态和最新日志，手机即可查看。\r\n\r\n系统安全\r\n使用阿里云云主机，借助阿里云本身防护机制，\r\n\r\n在主机中安装denyhosts，对于尝试暴力破解ssh的IP，实施封禁\r\n\r\n对于评论部分，能够抵御sql注入和xss攻击\r\n\r\n打包测试\r\n使用springboot本身测试方式，在集成测试之前，先进行单元测试\r\n\r\n打包，使用springboot的mvn插件，打成jar包\r\n\r\n网站建设\r\n服务器选用的是阿里云centos7\r\n域名是腾讯送的\r\n网站需要备案，备案的话，只要按照阿里云提示的流程走，就可以了，就是上传个人身份信息，和审核，大概需要一个月的时间\r\n开发总结\r\nspringboot常用注解\r\n\r\nsrpingboot整合mybatis\r\n\r\nspringboot之邮件的发送\r\n\r\nspringboot之thymeleaf的使用\r\n\r\nspringboot之定时任务\r\n\r\nspringboot之netty的使用\r\n\r\nspringboot之redis的整合与使用\r\n\r\n以上是我学习springboot总结的一些博客，特此分享\r\n\r\n网站地址\r\n[www.janti.cn](http://www.janti.cn)\r\n\r\n[项目代码](https://github.com/972152412/Jantent)', '1', 'post', 'publish', 'springboot', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('2', 'springboot常用注解', 'article2', '1546854433', '1546939307', 'springboot常用注解\r\n发布于 2018-05-09\r\n概述\r\n本文主要整理springboot中的常用注解，主要是平时开发中经常使用的，部分注解会以说明和例子的形式进行讲解。\r\n\r\n@SpringBootApplication\r\n说明\r\n@SpringBootApplication 注解等价于以默认属性使用 @Configuration ， @EnableAutoConfiguration 和 @ComponentScan 。通常使用在有main方法中类中注解。\r\n\r\n例子\r\npackage com;\r\n\r\nimport com.server.NettyTcpServer;\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\nimport org.springframework.context.annotation.ComponentScan;\r\n\r\nimport javax.annotation.Resource;\r\n\r\n@SpringBootApplication\r\npublic class StartApplication {\r\n\r\n    public static void main(String args[])throws Exception{\r\n        SpringApplication.run(StartApplication.class,args);\r\n    }\r\n\r\n}\r\n\r\n@Bean\r\n说明\r\n产生一个bean的方法，并且交给Spring容器管理\r\n可理解为用spring的时候xml里面的标签\r\n该注解是用于方法上的，就是用来产生一个Bean\r\n注解分为两类：\r\n一类是使用Bean，即是把已经在xml文件中配置好的Bean拿来用，完成属性、方法的组装；比如@Autowired , @Resource，可以通过byTYPE（@Autowired）、byNAME（@Resource）的方式获取Bean；\r\n一类是注册Bean,@Component , @Repository , @ Controller , @Service , @Configration这些注解都是把你要实例化的对象转化成一个Bean，放在IoC容器中，等你要用的时候，它会和上面的@Autowired , @Resource配合到一起，把对象、属性、方法完美组装。\r\n例子\r\n    @Bean(name = \"clientbootstrap\")\r\n    public Bootstrap clientBootSrap() throws Exception {\r\n        Bootstrap bootstrap = new Bootstrap();\r\n        bootstrap.group(clientGroup())\r\n                .channel(NioSocketChannel.class)\r\n                .option(ChannelOption.TCP_NODELAY, true)\r\n                .option(ChannelOption.SO_KEEPALIVE, true)\r\n                .handler(clientInitializer);\r\n        return bootstrap;\r\n    }\r\n@ComponentScan\r\n组件扫描。个人理解相当于context:component-scan，如果扫描到有@Component @Controller @Service等这些注解的类，则把这些类注册为bean。\r\n\r\n@ControllerAdvice\r\n说明\r\n注解定义全局异常处理类\r\n\r\n@ExceptionHandler\r\n说明\r\n注解声明异常处理方法 通常@ControllerAdvice和@ExceptionHandler结合使用：\r\n\r\n@ControllerAdvice\r\npublic class GlobalExceptionHandler {\r\n\r\n    @ExceptionHandler(Exception.class)\r\n    String handleException(){\r\n        return \"Exception Deal!\";\r\n    }\r\n}\r\n方法 handleException() 就会处理所有 Controller 层抛出的 Exception 及其子类的异常，这是最基本的用法了。\r\n\r\n@value\r\n说明\r\n该注解可以springboot中的配置文件中的参数值，使用@Value的类如果被其他类作为对象引用，必须要使用注入的方式，而不能new。\r\n该注解非常有用，通常一些配置，比如http服务的端口，可以在写配置文件中。\r\n例子：\r\napplication.yml中的自定义配置如下，\r\n\r\ntcp:\r\n  port: 3018\r\n  ip: 127.0.0.1\r\n使用的时候：\r\n\r\n    @Value(\"${tcp.port}\")\r\n    private int tcpPort;\r\n\r\n    @Value((\"${tcp.ip}\"))\r\n    private String serverIp;\r\n@ResponseBody\r\n说明\r\n表示该方法的返回结果直接写入HTTP response body中 一般在异步获取数据时使用，在使用@RequestMapping后，返回值通常解析为跳转路径，加上 @responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如 异步获取json数据，加上@responsebody后，会直接返回json数据。\r\n\r\n@Controller\r\n说明\r\n控制器Controller 负责处理由DispatcherServlet 分发的请求，它把用户请求的数据经过业务处理层处理之后封装成一个Model ，然后再把该Model 返回给对应的View 进行展示。\r\n\r\n在SpringMVC 中提供了一个非常简便的定义Controller 的方法，你无需继承特定的类或实现特定的接口，只需使用@Controller 标记一个类是Controller ，然后使用@RequestMapping 和@RequestParam 等一些注解用以定义URL 请求和Controller 方法之间的映射，这样的Controller 就能被外界访问到。\r\n\r\n此外Controller 不会直接依赖于HttpServletRequest 和HttpServletResponse 等HttpServlet 对象，它们可以通过Controller 的方法参数灵活的获取到\r\n\r\n用于标记在一个类上，使用它标记的类就是一个SpringMVC Controller 对象。分发处理器将会扫描使用了该注解的类的方法，并检测该方法是否使用了@RequestMapping 注解\r\n\r\n例子\r\n@Controller\r\npublic class MyController {\r\n    @RequestMapping ( \"/showView\" )\r\n    public ModelAndView showView() {\r\n       ModelAndView modelAndView = new ModelAndView();\r\n       modelAndView.setViewName( \"viewName\" );\r\n       modelAndView.addObject( \" helloworld \" );\r\n       return modelAndView;\r\n    }\r\n\r\n} \r\n@RestController\r\n说明\r\n@RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用\r\n\r\n@ComponentScan\r\n说明\r\n组件扫描，可自动发现和装配一些Bean。\r\n\r\n@Qualifier\r\n说明\r\n当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者。\r\n\r\n例子\r\n@Autowired \r\n@Qualifier(value = “demoInfoService”) \r\nprivate DemoInfoService demoInfoService;\r\n注入\r\n@Autowired和@Resource\r\n说明\r\n@Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。\r\n\r\n@Autowired默认按类型装配（这个注解是属业spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下：\r\n\r\n@Autowired() @Qualifier(\"baseDao\")    \r\nprivate BaseDao baseDao;\r\n@Resource 是JDK1.6支持的注解，默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名，按照名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。\r\n他们的主要区别就是@Autowired是默认按照类型装配的 @Resource默认是按照名称装配的byName 通过参数名 自动装配，如果一个bean的name 和另外一个bean的 property 相同，就自动装配。byType 通过参数的数据类型自动自动装配，如果一个bean的数据类型和另外一个bean的property属性的数据类型兼容，就自动装我们可以通过 @Autowired 或 @Resource 在 Bean 类中使用自动注入功能，但是 Bean 还是在 XML 文件中通过 进行定义 —— 也就是说，在 XML 配置文件中定义 Bean，通过@Autowired 或 @Resource 为 Bean 的成员变量、方法入参或构造函数入参提供自动注入的功能。', '1', 'post', 'publish', 'springboot', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('3', 'springboot之netty整合', 'article3', '1546854723', '1547189248', 'springboot之netty整合\r\n发布于 2018-05-07\r\n概述\r\n在实际的生产项目中，尤其是soa架构的系统。会用到网络传输的接口。首先会想到的springboot+netty的方式。springboot不用多说，火的不行，netty在很多实际项目中都有运用，非常好的一个框架，开发非常方便。 本文主要内容是：\r\n\r\nspringboot与netty的整合\r\nnetty简单的长连接\r\npom文件\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>1.5.1.RELEASE</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n    <dependencies>\r\n        <!-- netty -->\r\n        <dependency>\r\n            <groupId>io.netty</groupId>\r\n            <artifactId>netty-all</artifactId>\r\n            <version>4.1.17.Final</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n        <!-- spring boot 热部署-->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-devtools</artifactId>\r\n            <optional>true</optional>\r\n        </dependency>\r\n\r\n    </dependencies>\r\n服务端的配置\'\r\n配置文件\r\n首先在application.yml中写入netty服务端依赖的配置. 这里配置了三个参数，一个是服务端的端口，group的线程池的大小。 如下所示：\r\n\r\ntcp:\r\n  port: 3018\r\nboss:\r\n  thread:\r\n    count: 2\r\nworker:\r\n  thread:\r\n    count: 2\r\n配置类\r\nnetty和springboot整合的时候，就需要将类加载交给spring的加载器,和平时写service类很类似。 首先先写handler类,这里这是很简单的示范，没有具体的业务实现，一般情况都是都是用json做数据，这里我偷懒了一下。\r\n\r\n内容如下：\r\n\r\npackage com.server.handler;\r\n\r\nimport io.netty.buffer.ByteBuf;\r\nimport io.netty.buffer.Unpooled;\r\nimport io.netty.channel.ChannelHandler;\r\nimport io.netty.channel.ChannelHandlerContext;\r\nimport io.netty.channel.SimpleChannelInboundHandler;\r\nimport org.springframework.stereotype.Component;\r\n\r\n@Component\r\n@ChannelHandler.Sharable\r\npublic class TcpHandler extends SimpleChannelInboundHandler<String>{\r\n\r\n    @Override\r\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\r\n        System.out.println(\"服务单收到消息如下：\"+msg);\r\n        String remsg = \"服务端的响应\";\r\n        ByteBuf byteBuf = Unpooled.wrappedBuffer(remsg.getBytes(\"utf-8\"));\r\n        ctx.writeAndFlush(byteBuf);\r\n    }\r\n\r\n    @Override\r\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {\r\n        cause.printStackTrace();\r\n        ctx.close();\r\n    }\r\n\r\n}\r\n\r\nServerInitializer类，这里集成pipeline\r\n\r\npackage com.server.handler;\r\n\r\nimport io.netty.channel.ChannelInitializer;\r\nimport io.netty.channel.ChannelPipeline;\r\nimport io.netty.channel.socket.SocketChannel;\r\nimport io.netty.handler.codec.string.StringDecoder;\r\nimport io.netty.handler.codec.string.StringEncoder;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.stereotype.Component;\r\n\r\n@Component\r\npublic class ServerInitializer extends ChannelInitializer<SocketChannel>{\r\n\r\n    @Autowired\r\n    TcpHandler tcpHandler;\r\n\r\n    @Override\r\n    protected void initChannel(SocketChannel ch) throws Exception {\r\n        ChannelPipeline pipeline = ch.pipeline();\r\n        pipeline.addLast(\"decoder\",new StringDecoder());\r\n        pipeline.addLast(\"encoder\",new StringEncoder());\r\n        pipeline.addLast(\"handler\",tcpHandler);\r\n    }\r\n}\r\n\r\n下面的内容是重点了，这里主要是利用springboot自带的application.yml配置文件，来记录配置信息。 使用：\r\n\r\n    @Value(\"${boss.thread.count}\")\r\n    private int bossCount;\r\n\r\n的方式，就可以读出配置文件的内容，是不是很方便。 下面是服务端具体配置的内容：\r\n\r\npackage com.config;\r\n\r\nimport com.server.handler.ServerInitializer;\r\nimport io.netty.bootstrap.ServerBootstrap;\r\nimport io.netty.channel.ChannelOption;\r\nimport io.netty.channel.nio.NioEventLoopGroup;\r\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.beans.factory.annotation.Value;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.Configuration;\r\n\r\nimport java.net.InetSocketAddress;\r\n\r\n/**\r\n * @author janti\r\n * netty服务端配置类\r\n */\r\n@Configuration\r\npublic class NettyServerConfig {\r\n\r\n    @Value(\"${boss.thread.count}\")\r\n    private int bossCount;\r\n\r\n    @Value(\"${worker.thread.count}\")\r\n    private int workerCount;\r\n\r\n    // 服务端的端口\r\n    @Value(\"${tcp.port}\")\r\n    private int tcpPort;\r\n\r\n    @Autowired\r\n    private ServerInitializer serverInitializer;\r\n\r\n    /**\r\n     * 将bootstarp由spring托管\r\n     * @return\r\n     */\r\n    @Bean(name = \"serverBootStarp\")\r\n    public ServerBootstrap bootstrap() {\r\n        ServerBootstrap bootstrap = new ServerBootstrap();\r\n        bootstrap.group(bossGroup(), workerGroup())\r\n                .channel(NioServerSocketChannel.class)\r\n                .childHandler(serverInitializer)\r\n                // 保持连接\r\n                .option(ChannelOption.SO_KEEPALIVE, true)\r\n                .option(ChannelOption.TCP_NODELAY, true);\r\n\r\n        return bootstrap;\r\n    }\r\n\r\n    @Bean(name = \"bossGroup\", destroyMethod = \"shutdownGracefully\")\r\n    public NioEventLoopGroup bossGroup() {\r\n        return new NioEventLoopGroup(bossCount);\r\n    }\r\n\r\n    @Bean(name = \"bossGroup\", destroyMethod = \"shutdownGracefully\")\r\n    public NioEventLoopGroup workerGroup() {\r\n        return new NioEventLoopGroup(workerCount);\r\n    }\r\n\r\n    @Bean\r\n    public InetSocketAddress tcpPort() {\r\n        return new InetSocketAddress(tcpPort);\r\n    }\r\n}\r\n\r\n好的配置完毕了，接下来服务端的启动和关闭了。 这里使用了@PostConstruct和@PreDestroy注解， 从Java EE 5规范开始，Servlet中增加了两个影响Servlet生命周期的注解（Annotion）；@PostConstruct和@PreDestroy。这两个注解被用来修饰一个非静态的void()方法。\r\n\r\n启动类：\r\n\r\npackage com.server;\r\n\r\nimport io.netty.bootstrap.ServerBootstrap;\r\nimport io.netty.channel.ChannelFuture;\r\nimport org.springframework.stereotype.Component;\r\n\r\nimport javax.annotation.PostConstruct;\r\nimport javax.annotation.PreDestroy;\r\nimport javax.annotation.Resource;\r\nimport java.net.InetSocketAddress;\r\n\r\n@Component\r\npublic class NettyTcpServer {\r\n\r\n    @Resource\r\n    private ServerBootstrap bootstrap;\r\n\r\n    @Resource\r\n    private InetSocketAddress tcpPort;\r\n\r\n    private ChannelFuture serverChannelFuture;\r\n\r\n    /**\r\n     * 在启动servlet的时候，启动netty\r\n     * @throws Exception\r\n     */\r\n    @PostConstruct\r\n    public void start() throws Exception{\r\n        System.out.printf(\"netty服务器启动\");\r\n        serverChannelFuture = bootstrap.bind(tcpPort);\r\n        serverChannelFuture.channel().closeFuture().sync();\r\n    }\r\n\r\n    /**\r\n     * servlet关闭的时候，关闭netty服务\r\n     * @throws Exception\r\n     */\r\n    @PreDestroy\r\n    public void stop() throws Exception{\r\n        serverChannelFuture.channel().closeFuture().sync();\r\n    }\r\n}\r\n好了，接下来启动springboot的启动类，即可以启动netty服务。你可以使用Telnet测试一下。 想要源码的可以戳这里，记得给个star 服务端的代码\r\n\r\nnetty客户端\r\nnetty客户端的整合和服务端的是大同小异。这里我直接贴代码了。\r\n\r\nhandler类\r\n\r\npackage com.client.handler;\r\n\r\nimport io.netty.channel.ChannelHandlerContext;\r\nimport io.netty.channel.SimpleChannelInboundHandler;\r\nimport org.springframework.stereotype.Component;\r\n\r\n/**\r\n * @author janti\r\n * @date 2018/5/6 22:59\r\n */\r\n@Component\r\npublic class ClientHandler extends SimpleChannelInboundHandler<String>{\r\n    @Override\r\n    public void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\r\n\r\n        System.out.println(\"客户端收到消息\" + msg);\r\n    }\r\n\r\n    @Override\r\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {\r\n        cause.printStackTrace();\r\n        ctx.close();\r\n    }\r\n}\r\n\r\nInitializer类\r\n\r\npackage com.client.handler;\r\n\r\nimport io.netty.channel.ChannelInitializer;\r\nimport io.netty.channel.ChannelPipeline;\r\nimport io.netty.channel.socket.SocketChannel;\r\nimport io.netty.handler.codec.string.StringDecoder;\r\nimport io.netty.handler.codec.string.StringEncoder;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.stereotype.Component;\r\n\r\n/**\r\n * @author janti\r\n * @date 2018/5/6 22:54\r\n */\r\n@Component\r\npublic class ClientInitializer extends ChannelInitializer<SocketChannel> {\r\n\r\n\r\n    @Autowired\r\n    ClientHandler clientHandler;\r\n\r\n    @Override\r\n    protected void initChannel(SocketChannel ch) throws Exception {\r\n        ChannelPipeline pipeline = ch.pipeline();\r\n        pipeline.addLast(\"encoder\",new StringEncoder());\r\n        pipeline.addLast(\"decoder\",new StringDecoder());\r\n        pipeline.addLast(\"handler\",clientHandler);\r\n    }\r\n}\r\n\r\nconfig类：\r\n\r\npackage com.config;\r\n\r\nimport com.client.handler.ClientInitializer;\r\nimport io.netty.bootstrap.Bootstrap;\r\nimport io.netty.channel.ChannelOption;\r\nimport io.netty.channel.nio.NioEventLoopGroup;\r\nimport io.netty.channel.socket.nio.NioSocketChannel;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.stereotype.Component;\r\n\r\n@Component\r\npublic class NettyClientConfig {\r\n    @Autowired\r\n    private ClientInitializer clientInitializer;\r\n\r\n    @Bean(name = \"clientbootstrap\")\r\n    public Bootstrap clientBootSrap() throws Exception {\r\n        Bootstrap bootstrap = new Bootstrap();\r\n        bootstrap.group(clientGroup())\r\n                .channel(NioSocketChannel.class)\r\n                .option(ChannelOption.TCP_NODELAY, true)\r\n                .option(ChannelOption.SO_KEEPALIVE, true)\r\n                .handler(clientInitializer);\r\n        return bootstrap;\r\n    }\r\n\r\n    @Bean(name = \"clientGroup\", destroyMethod = \"shutdownGracefully\")\r\n    public NioEventLoopGroup clientGroup() {\r\n        return new NioEventLoopGroup(2);\r\n    }\r\n}\r\n\r\n启动类：\r\n\r\npackage com.client;\r\n\r\nimport io.netty.bootstrap.Bootstrap;\r\nimport io.netty.buffer.ByteBuf;\r\nimport io.netty.buffer.Unpooled;\r\nimport io.netty.channel.Channel;\r\nimport io.netty.channel.ChannelFuture;\r\nimport org.springframework.beans.factory.annotation.Value;\r\nimport org.springframework.stereotype.Component;\r\n\r\nimport javax.annotation.PostConstruct;\r\nimport javax.annotation.Resource;\r\nimport java.io.UnsupportedEncodingException;\r\n\r\n@Component\r\npublic class NettyTcpClient {\r\n    @Resource\r\n    private Bootstrap bootstrap;\r\n\r\n    @Value(\"${tcp.port}\")\r\n    private int tcpPort;\r\n\r\n    @Value((\"${tcp.ip}\"))\r\n    private String serverIp;\r\n\r\n    private Channel channel;\r\n\r\n    @PostConstruct\r\n    public void connect() throws Exception {\r\n        // 发起异步连接\r\n        ChannelFuture future = bootstrap.connect(serverIp, tcpPort).sync();\r\n        channel = future.channel();\r\n        System.out.println(\"客户端连接成功\");\r\n        if (!future.isSuccess()) {\r\n            future.cause().printStackTrace();\r\n        }\r\n    }\r\n\r\n    public void stop() throws Exception {\r\n        channel.close();\r\n    }\r\n\r\n    /**\r\n     * 发送消息 使用方法即可\r\n     * @param msg\r\n     */\r\n    public void sendMessage(String msg) {\r\n        try {\r\n            for (int i = 0; i < 2; i++) {\r\n                ByteBuf byteBuf = Unpooled.wrappedBuffer(msg.getBytes(\"utf-8\"));\r\n                channel.writeAndFlush(byteBuf);\r\n                try {\r\n                    Thread.sleep(500);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        } catch (UnsupportedEncodingException e) {\r\n            System.out.println(\"数据发送失败\");\r\n        }\r\n\r\n    }\r\n}\r\n\r\n这样写的意图是，使用 @PostConstruct注解connect，在服务启动时，先获取连接并保持连接。 如果需要发送信息，直接使用sendMessage(String msg)即可。 客户端代码', '1', 'post', 'publish', 'springboot,netty', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('4', 'springboot之redis的整合与使用', 'article4', '1546854763', '1547189233', 'springboot之redis的整合与使用\r\n发布于 2018-05-04\r\n概述\r\n本文内容主要\r\n\r\n关于spring-redis\r\n关于redis的key设计\r\nredis的基本数据结构\r\n介绍redis与springboot的整合\r\nsringboot中的redistemplate的使用\r\n之前看了很多博客，大都都只是粗略的介绍，这里想要记录的全面一些，也算是一个学习的过程 首发于我的个人博客:janti的个人博客\r\n\r\n关于spring-redis\r\nspring-data-redis针对jedis提供了如下功能：\r\n\r\n1. 连接池自动管理，提供了一个高度封装的“RedisTemplate”类\r\n\r\n2. 针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口\r\n\r\nValueOperations：简单K-V操作\r\nSetOperations：set类型数据操作\r\nZSetOperations：zset类型数据操作\r\nHashOperations：针对map类型的数据操作\r\nListOperations：针对list类型的数据操作\r\n\r\n3. 提供了对key的“bound”(绑定)便捷化操作API，可以通过bound封装指定的key，然后进行一系列的操作而无须“显式”的再次指定Key，即BoundKeyOperations：\r\n\r\nBoundValueOperations\r\nBoundSetOperations\r\nBoundListOperations\r\nBoundSetOperations\r\nBoundHashOperations\r\n\r\n4. 将事务操作封装，有容器控制。\r\n\r\n5. 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)\r\n\r\nJdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream/ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。\r\n\r\nStringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。\r\n\r\nJacksonJsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。因为jackson工具在序列化和反序列化时，需要明确指定Class类型，因此此策略封装起来稍微复杂。【需要jackson-mapper-asl工具支持】\r\n\r\nOxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。【需要spring-oxm模块的支持】\r\n如果你的数据需要被第三方工具解析，那么数据应该使用StringRedisSerializer而不是JdkSerializationRedisSerializer。\r\n\r\n关于key的设计\r\nkey的存活时间：\r\n无论什么时候，只要有可能就利用key超时的优势。一个很好的例子就是储存一些诸如临时认证key之类的东西。当你去查找一个授权key时——以OAUTH为例——通常会得到一个超时时间。 这样在设置key的时候，设成同样的超时时间，Redis就会自动为你清除。\r\n\r\n关系型数据库的redis\r\n1: 把表名转换为key前缀 如, tag: 2: 第2段放置用于区分区key的字段--对应mysql中的主键的列名,如userid 3: 第3段放置主键值,如2,3,4...., a , b ,c 4: 第4段,写要存储的列名 例：user:userid:9:username\r\n\r\nRedis的数据类型\r\nString字符串\r\nstring是redis最基本的类型，一个key对应一个value。\r\nstring类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。\r\nstring类型是Redis最基本的数据类型，一个键最大能存储512MB。\r\nString类型的操作参考\r\n链表\r\nredis列表是简单的字符串列表，排序为插入的顺序。列表的最大长度为2^32-1。\r\n\r\nredis的列表是使用链表实现的，这意味着，即使列表中有上百万个元素，增加一个元素到列表的头部或尾部的操作都是在常量的时间完成。\r\n\r\n可以用列表获取最新的内容（像帖子，微博等），用ltrim很容易就会获取最新的内容，并移除旧的内容。\r\n\r\n用列表可以实现生产者消费者模式，生产者调用lpush添加项到列表中，消费者调用rpop从列表中提取，如果没有元素，则轮询去获取，或者使用brpop等待生产者添加项到列表中。\r\n\r\nList类型的操作参考\r\n\r\n集合\r\nredis集合是无序的字符串集合，集合中的值是唯一的，无序的。可以对集合执行很多操作，例如，测试元素是否存在，对多个集合执行交集、并集和差集等等。\r\n我们通常可以用集合存储一些无关顺序的，表达对象间关系的数据，例如用户的角色，可以用sismember很容易就判断用户是否拥有某个角色。\r\n在一些用到随机值的场合是非常适合的，可以用 srandmember/spop 获取/弹出一个随机元素。 同时，使用@EnableCaching开启声明式缓存支持，这样就可以使用基于注解的缓存技术。注解缓存是一个对缓存使用的抽象，通过在代码中添加下面的一些注解，达到缓存的效果。\r\nSet类型的操作参考\r\nZSet 有序集合\r\n有序集合由唯一的，不重复的字符串元素组成。有序集合中的每个元素都关联了一个浮点值，称为分数。可以把有序看成hash和集合的混合体，分数即为hash的key。\r\n\r\n有序集合中的元素是按序存储的，不是请求时才排序的。\r\n\r\nZSet类型的操作类型\r\n\r\nHash-哈希\r\nredis的哈希值是字符串字段和字符串之间的映射，是表示对象的完美数据类型。\r\n\r\n哈希中的字段数量没有限制，所以可以在你的应用程序以不同的方式来使用哈希。\r\n\r\nHash类型的操作参考\r\n\r\nspringboot 与redis的整合\r\npom文件\r\n依赖如下：\r\n\r\n   <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>1.5.1.RELEASE</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n    <dependencies>\r\n        <!-- spring boot 配置 -->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-data-redis</artifactId>\r\n        </dependency>\r\n\r\n\r\n    </dependencies>\r\napplication.properties\r\n# Redis数据库索引（默认为0）\r\nspring.redis.database=0  \r\n# Redis服务器地址\r\nspring.redis.host=127.0.0.1\r\n# Redis服务器连接端口\r\nspring.redis.port=6379  \r\n# Redis服务器连接密码（默认为空）\r\nspring.redis.password=\r\n# 连接池最大连接数（使用负值表示没有限制）\r\nspring.redis.pool.max-active=8  \r\n# 连接池最大阻塞等待时间（使用负值表示没有限制）\r\nspring.redis.pool.max-wait=-1  \r\n# 连接池中的最大空闲连接\r\nspring.redis.pool.max-idle=8  \r\n# 连接池中的最小空闲连接\r\nspring.redis.pool.min-idle=0  \r\n# 连接超时时间（毫秒）\r\nspring.redis.timeout=0  \r\nredisTemplate的配置\r\n新建一个redisConfig类，进行相关bean的配置：\r\n\r\npackage com.config;\r\n\r\nimport com.fasterxml.jackson.annotation.JsonAutoDetect;\r\nimport com.fasterxml.jackson.annotation.PropertyAccessor;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport org.springframework.cache.CacheManager;\r\nimport org.springframework.cache.annotation.CachingConfigurerSupport;\r\nimport org.springframework.cache.annotation.EnableCaching;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.Configuration;\r\nimport org.springframework.data.redis.cache.RedisCacheManager;\r\nimport org.springframework.data.redis.connection.RedisConnectionFactory;\r\nimport org.springframework.data.redis.core.*;\r\nimport org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;\r\nimport org.springframework.data.redis.serializer.StringRedisSerializer;\r\n\r\n/**\r\n * @author janti\r\n * reids 相关bean的配置\r\n */\r\n@Configuration\r\n@EnableCaching\r\npublic class RedisConfig extends CachingConfigurerSupport {\r\n\r\n    /**\r\n     * 选择redis作为默认缓存工具\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public CacheManager cacheManager(RedisTemplate redisTemplate) {\r\n        RedisCacheManager rcm = new RedisCacheManager(redisTemplate);\r\n        return rcm;\r\n    }\r\n\r\n    /**\r\n     * retemplate相关配置\r\n     * @param factory\r\n     * @return\r\n     */\r\n    @Bean\r\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\r\n\r\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\r\n        // 配置连接工厂\r\n        template.setConnectionFactory(factory);\r\n\r\n        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）\r\n        Jackson2JsonRedisSerializer jacksonSeial = new Jackson2JsonRedisSerializer(Object.class);\r\n\r\n        ObjectMapper om = new ObjectMapper();\r\n        // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public\r\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\r\n        // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常\r\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\r\n        jacksonSeial.setObjectMapper(om);\r\n\r\n        // 值采用json序列化\r\n        template.setValueSerializer(jacksonSeial);\r\n        //使用StringRedisSerializer来序列化和反序列化redis的key值\r\n        template.setKeySerializer(new StringRedisSerializer());\r\n\r\n        // 设置hash key 和value序列化模式\r\n        template.setHashKeySerializer(new StringRedisSerializer());\r\n        template.setHashValueSerializer(jacksonSeial);\r\n        template.afterPropertiesSet();\r\n\r\n        return template;\r\n    }\r\n\r\n    /**\r\n     * 对hash类型的数据操作\r\n     *\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public HashOperations<String, String, Object> hashOperations(RedisTemplate<String, Object> redisTemplate) {\r\n        return redisTemplate.opsForHash();\r\n    }\r\n\r\n    /**\r\n     * 对redis字符串类型数据操作\r\n     *\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public ValueOperations<String, Object> valueOperations(RedisTemplate<String, Object> redisTemplate) {\r\n        return redisTemplate.opsForValue();\r\n    }\r\n\r\n    /**\r\n     * 对链表类型的数据操作\r\n     *\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public ListOperations<String, Object> listOperations(RedisTemplate<String, Object> redisTemplate) {\r\n        return redisTemplate.opsForList();\r\n    }\r\n\r\n    /**\r\n     * 对无序集合类型的数据操作\r\n     *\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public SetOperations<String, Object> setOperations(RedisTemplate<String, Object> redisTemplate) {\r\n        return redisTemplate.opsForSet();\r\n    }\r\n\r\n    /**\r\n     * 对有序集合类型的数据操作\r\n     *\r\n     * @param redisTemplate\r\n     * @return\r\n     */\r\n    @Bean\r\n    public ZSetOperations<String, Object> zSetOperations(RedisTemplate<String, Object> redisTemplate) {\r\n        return redisTemplate.opsForZSet();\r\n    }\r\n}\r\n\r\n\r\nspring-redis中使用了RedisTemplate来进行redis的操作，通过泛型的K和V设置键值对的对象类型。这里使用了string作为key的对象类型，值为Object。\r\n\r\n对于Object，spring-redis默认使用了jdk自带的序列化，不推荐使用默认了。所以使用了json的序列化方式\r\n\r\n对spring-redis对redis的五种数据类型也有支持\r\n\r\nHashOperations：对hash类型的数据操作\r\n\r\nValueOperations：对redis字符串类型数据操作\r\n\r\nListOperations：对链表类型的数据操作\r\n\r\nSetOperations：对无序集合类型的数据操作\r\n\r\nZSetOperations：对有序集合类型的数据操作\r\n\r\nredis操作的工具类\r\npackage com.service;\r\n\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.data.redis.core.RedisTemplate;\r\nimport org.springframework.stereotype.Component;\r\n\r\nimport java.util.Collection;\r\nimport java.util.Date;\r\nimport java.util.Set;\r\nimport java.util.concurrent.TimeUnit;\r\nimport java.util.stream.Collectors;\r\nimport java.util.stream.Stream;\r\n\r\n@Component\r\npublic class RedisService {\r\n    @Autowired\r\n    private RedisTemplate<String, String> redisTemplate;\r\n\r\n    /**\r\n     * 默认过期时长，单位：秒\r\n     */\r\n    public static final long DEFAULT_EXPIRE = 60 * 60 * 24;\r\n\r\n    /**\r\n     * 不设置过期时长\r\n     */\r\n    public static final long NOT_EXPIRE = -1;\r\n\r\n\r\n\r\n\r\n    public boolean existsKey(String key) {\r\n        return redisTemplate.hasKey(key);\r\n    }\r\n\r\n    /**\r\n     * 重名名key，如果newKey已经存在，则newKey的原值被覆盖\r\n     *\r\n     * @param oldKey\r\n     * @param newKey\r\n     */\r\n    public void renameKey(String oldKey, String newKey) {\r\n        redisTemplate.rename(oldKey, newKey);\r\n    }\r\n\r\n    /**\r\n     * newKey不存在时才重命名\r\n     *\r\n     * @param oldKey\r\n     * @param newKey\r\n     * @return 修改成功返回true\r\n     */\r\n    public boolean renameKeyNotExist(String oldKey, String newKey) {\r\n        return redisTemplate.renameIfAbsent(oldKey, newKey);\r\n    }\r\n\r\n    /**\r\n     * 删除key\r\n     *\r\n     * @param key\r\n     */\r\n    public void deleteKey(String key) {\r\n        redisTemplate.delete(key);\r\n    }\r\n\r\n    /**\r\n     * 删除多个key\r\n     *\r\n     * @param keys\r\n     */\r\n    public void deleteKey(String... keys) {\r\n        Set<String> kSet = Stream.of(keys).map(k -> k).collect(Collectors.toSet());\r\n        redisTemplate.delete(kSet);\r\n    }\r\n\r\n    /**\r\n     * 删除Key的集合\r\n     *\r\n     * @param keys\r\n     */\r\n    public void deleteKey(Collection<String> keys) {\r\n        Set<String> kSet = keys.stream().map(k -> k).collect(Collectors.toSet());\r\n        redisTemplate.delete(kSet);\r\n    }\r\n\r\n    /**\r\n     * 设置key的生命周期\r\n     *\r\n     * @param key\r\n     * @param time\r\n     * @param timeUnit\r\n     */\r\n    public void expireKey(String key, long time, TimeUnit timeUnit) {\r\n        redisTemplate.expire(key, time, timeUnit);\r\n    }\r\n\r\n    /**\r\n     * 指定key在指定的日期过期\r\n     *\r\n     * @param key\r\n     * @param date\r\n     */\r\n    public void expireKeyAt(String key, Date date) {\r\n        redisTemplate.expireAt(key, date);\r\n    }\r\n\r\n    /**\r\n     * 查询key的生命周期\r\n     *\r\n     * @param key\r\n     * @param timeUnit\r\n     * @return\r\n     */\r\n    public long getKeyExpire(String key, TimeUnit timeUnit) {\r\n        return redisTemplate.getExpire(key, timeUnit);\r\n    }\r\n\r\n    /**\r\n     * 将key设置为永久有效\r\n     *\r\n     * @param key\r\n     */\r\n    public void persistKey(String key) {\r\n        redisTemplate.persist(key);\r\n    }\r\n\r\n\r\n}\r\n\r\nredis的key工具类\r\npackage com.util;\r\n\r\n/**\r\n * redisKey设计\r\n */\r\npublic class RedisKeyUtil {\r\n\r\n    /**\r\n     * redis的key\r\n     * 形式为：\r\n     * 表名:主键名:主键值:列名\r\n     *\r\n     * @param tableName 表名\r\n     * @param majorKey 主键名\r\n     * @param majorKeyValue 主键值\r\n     * @param column 列名\r\n     * @return\r\n     */\r\n    public static String getKeyWithColumn(String tableName,String majorKey,String majorKeyValue,String column){\r\n        StringBuffer buffer = new StringBuffer();\r\n        buffer.append(tableName).append(\":\");\r\n        buffer.append(majorKey).append(\":\");\r\n        buffer.append(majorKeyValue).append(\":\");\r\n        buffer.append(column);\r\n        return buffer.toString();\r\n    }\r\n    /**\r\n     * redis的key\r\n     * 形式为：\r\n     * 表名:主键名:主键值\r\n     *\r\n     * @param tableName 表名\r\n     * @param majorKey 主键名\r\n     * @param majorKeyValue 主键值\r\n     * @return\r\n     */\r\n    public static String getKey(String tableName,String majorKey,String majorKeyValue){\r\n        StringBuffer buffer = new StringBuffer();\r\n        buffer.append(tableName).append(\":\");\r\n        buffer.append(majorKey).append(\":\");\r\n        buffer.append(majorKeyValue).append(\":\");\r\n        return buffer.toString();\r\n    }\r\n}\r\n\r\n如何使用？\r\n测试代码\r\n新建一个实体类：\r\n\r\npackage com.domain;\r\n\r\npublic class UserVo {\r\n\r\n    public  static final String Table = \"t_user\";\r\n\r\n    private String name;\r\n    private String address;\r\n    private Integer age;\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n\r\n    public String getAddress() {\r\n        return address;\r\n    }\r\n\r\n    public void setAddress(String address) {\r\n        this.address = address;\r\n    }\r\n\r\n    public Integer getAge() {\r\n        return age;\r\n    }\r\n\r\n    public void setAge(Integer age) {\r\n        this.age = age;\r\n    }\r\n\r\n\r\n    @Override\r\n    public String toString() {\r\n        return \"UserVo{\" +\r\n                \"name=\'\" + name + \'\\\'\' +\r\n                \", address=\'\" + address + \'\\\'\' +\r\n                \", age=\" + age +\r\n                \'}\';\r\n    }\r\n}\r\n\r\n再新建一个测试类：\r\n\r\npackage com.config;\r\n\r\nimport com.domain.UserVo;\r\nimport com.service.RedisService;\r\nimport com.util.RedisKeyUtil;\r\nimport org.junit.Test;\r\nimport org.junit.runner.RunWith;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.boot.test.context.SpringBootTest;\r\nimport org.springframework.data.redis.core.*;\r\nimport org.springframework.test.context.junit4.SpringRunner;\r\n\r\nimport javax.annotation.Resource;\r\n\r\nimport java.util.Set;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\nimport static org.junit.Assert.*;\r\n\r\n@RunWith(SpringRunner.class)\r\n@SpringBootTest\r\npublic class RedisConfigTest {\r\n\r\n    @Autowired\r\n    private StringRedisTemplate stringRedisTemplate;\r\n\r\n    @Autowired\r\n    private RedisTemplate redisTemplate;\r\n\r\n    @Resource\r\n    private ValueOperations<String,Object> valueOperations;\r\n\r\n    @Autowired\r\n    private HashOperations<String, String, Object> hashOperations;\r\n\r\n    @Autowired\r\n    private ListOperations<String, Object> listOperations;\r\n\r\n    @Autowired\r\n    private SetOperations<String, Object> setOperations;\r\n\r\n    @Autowired\r\n    private ZSetOperations<String, Object> zSetOperations;\r\n\r\n    @Resource\r\n    private RedisService redisService;\r\n\r\n    @Test\r\n    public void testObj() throws Exception{\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"上海\");\r\n        userVo.setName(\"测试dfas\");\r\n        userVo.setAge(123);\r\n        ValueOperations<String,Object> operations = redisTemplate.opsForValue();\r\n        redisService.expireKey(\"name\",20, TimeUnit.SECONDS);\r\n        String key = RedisKeyUtil.getKey(UserVo.Table,\"name\",userVo.getName());\r\n        UserVo vo = (UserVo) operations.get(key);\r\n        System.out.println(vo);\r\n    }\r\n\r\n    @Test\r\n    public void testValueOption( )throws  Exception{\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"上海\");\r\n        userVo.setName(\"jantent\");\r\n        userVo.setAge(23);\r\n        valueOperations.set(\"test\",userVo);\r\n\r\n        System.out.println(valueOperations.get(\"test\"));\r\n    }\r\n\r\n    @Test\r\n    public void testSetOperation() throws Exception{\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"北京\");\r\n        userVo.setName(\"jantent\");\r\n        userVo.setAge(23);\r\n        UserVo auserVo = new UserVo();\r\n        auserVo.setAddress(\"n柜昂周\");\r\n        auserVo.setName(\"antent\");\r\n        auserVo.setAge(23);\r\n        setOperations.add(\"user:test\",userVo,auserVo);\r\n        Set<Object> result = setOperations.members(\"user:test\");\r\n        System.out.println(result);\r\n    }\r\n\r\n    @Test\r\n    public void HashOperations() throws Exception{\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"北京\");\r\n        userVo.setName(\"jantent\");\r\n        userVo.setAge(23);\r\n        hashOperations.put(\"hash:user\",userVo.hashCode()+\"\",userVo);\r\n        System.out.println(hashOperations.get(\"hash:user\",userVo.hashCode()+\"\"));\r\n    }\r\n\r\n    @Test\r\n    public void  ListOperations() throws Exception{\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"北京\");\r\n        userVo.setName(\"jantent\");\r\n        userVo.setAge(23);\r\n//        listOperations.leftPush(\"list:user\",userVo);\r\n//        System.out.println(listOperations.leftPop(\"list:user\"));\r\n        // pop之后 值会消失\r\n        System.out.println(listOperations.leftPop(\"list:user\"));\r\n    }\r\n}\r\n注解缓存的使用\r\n@Cacheable：在方法执行前Spring先查看缓存中是否有数据，如果有数据，则直接返回缓存数据；没有则调用方法并将方法返回值放进缓存。\r\n\r\n@CachePut：将方法的返回值放到缓存中。\r\n\r\n@CacheEvict：删除缓存中的数据。\r\n\r\n最后所有的代码都被上传到我的github喜欢的话，给个start\r\n\r\n参考： Redis 学习(二) —— 数据类型及操作 安装参考', '1', 'post', 'publish', 'springboot,redis', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('5', 'springboot打包启动测试', 'article5', '1546854800', '1546939221', 'springboot打包启动测试\r\n发布于 2018-05-04\r\n打包\r\n如果是使用maven来管理项目的，那么需要在pow文件中加入springboot的maven补丁。内容如下：\r\n\r\n    <properties>\r\n        <java.version>1.8</java.version>\r\n        <!-- 跳过测试 -->\r\n        <skipTests>true</skipTests>\r\n    </properties>\r\n    <packaging>jar</packaging>\r\n\r\n    <!-- srpingboot maven打包补丁 -->\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n执行打包命令 mvn clean package,打出来的包会以项目名+版本号的形式放在target目录下\r\n\r\n启动的方式是\r\n\r\njava -jar  target/janti-1.0.0.jar\r\n第一次部署spring boot 到linux上，用命令java -jar **.jar，发现应用自动退出，进程停止了。后来发现要不挂断的执行命令，忽略所有的挂断信号，用以下命令解决\r\n\r\nnohup java -jar **.jar &\r\n\r\nnohup: 不挂断的执行命令，忽略所有的挂断信号。 运行后台命令 最后加 & ,这样就不会占用控制台了。\r\n\r\n测试\r\nsrpingboot对单元测试的支持很完善，需要引入以下这个依赖：\r\n\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-test</artifactId>\r\n    <scope>test</scope>\r\n</dependency>\r\n如何单元测试\r\n单元测试，最常用的是junit。首先生成改代码的测试类，然后加入\r\n\r\n@RunWith(SpringRunner.class)\r\n@SpringBootTest\r\n这两个注解。测试环境就搭好了。全部的代码如下：\r\n\r\n@RunWith(SpringRunner.class)\r\n@SpringBootTest\r\npublic class ClientConfigTest {\r\n\r\n    @Test\r\n    public void testClient()throws Exception{\r\n        System.out.println(\"test\")；\r\n    }\r\n}\r\n该方法通常用于service层，dao层的测试，对于controller层，springboot也给予了支持。 内容如下：\r\n\r\npublic class HelloControlerTests {\r\n\r\n    private MockMvc mvc;\r\n\r\n    //初始化执行\r\n    @Before\r\n    public void setUp() throws Exception {\r\n        mvc = MockMvcBuilders.standaloneSetup(new HelloController()).build();\r\n    }\r\n\r\n    //验证controller是否正常响应并打印返回结果\r\n    @Test\r\n    public void getHello() throws Exception {\r\n        mvc.perform(MockMvcRequestBuilders.get(\"/hello\").accept(MediaType.APPLICATION_JSON))\r\n                .andExpect(MockMvcResultMatchers.status().isOk())\r\n                .andDo(MockMvcResultHandlers.print())\r\n                .andReturn();\r\n    }\r\n    \r\n    //验证controller是否正常响应并判断返回结果是否正确\r\n    @Test\r\n    public void testHello() throws Exception {\r\n        mvc.perform(MockMvcRequestBuilders.get(\"/hello\").accept(MediaType.APPLICATION_JSON))\r\n                .andExpect(status().isOk())\r\n                .andExpect(content().string(equalTo(\"Hello World\")));\r\n    }\r\n\r\n}\r\n最好单元测试是程序员的修养体现，不要所有的事情都拖到集成测试中。\r\n\r\n集成测试\r\n集成测试，需要启动服务。既然是调试，难免会碰到测试，修改代码之后再重启服务的话会浪费很多时间。springboot同时只是热部署，只需要在pom中加入以下依赖即可：\r\n\r\n <dependencies>\r\n    <dependency>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-devtools</artifactId>\r\n        <optional>true</optional>\r\n    </dependency>\r\n</dependencies>\r\n\r\n<build>\r\n    <plugins>\r\n        <plugin>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-maven-plugin</artifactId>\r\n            <configuration>\r\n                <fork>true</fork>\r\n            </configuration>\r\n        </plugin>\r\n</plugins>\r\n</build>\r\n参考：link', '1', 'post', 'publish', 'springboot', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('6', 'springboot之定时任务', 'article6', '1546854844', '1546939201', 'springboot之定时任务\r\n发布于 2018-05-03\r\n定时线程\r\n说到定时任务，通常会想到JDK自带的定时线程来执行，定时任务。 回顾一下定时线程池。\r\n\r\npublic static ScheduledExecutorService newScheduledThreadPool(int var0) {\r\n        return new ScheduledThreadPoolExecutor(var0);\r\n    }\r\n\r\n    public static ScheduledExecutorService newScheduledThreadPool(int var0, ThreadFactory var1) {\r\n        return new ScheduledThreadPoolExecutor(var0, var1);\r\n    }\r\n常用的两个方法： scheduleAtFixedRate:是以固定的频率去执行任务，周期是指每次执行任务成功执行之间的间隔。\r\n\r\nschedultWithFixedDelay:是以固定的延时去执行任务，延时是指上一次执行成功之后和下一次开始执行的之前的时间。\r\n\r\n看一个DEMO：\r\n\r\npublic class ScheduledExecutorServiceDemo {\r\n    public static void main(String args[]) {\r\n\r\n        ScheduledExecutorService ses = Executors.newScheduledThreadPool(10);\r\n        ses.scheduleAtFixedRate(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                try {\r\n                    Thread.sleep(4000);\r\n                    System.out.println(Thread.currentThread().getId() + \"执行了\");\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }, 0, 2, TimeUnit.SECONDS);\r\n    }\r\n}\r\n具体细节我就不再赘述了，有兴趣的可以查看我关于线程池的博客：链接\r\n\r\nspringboot的定时任务\r\npom的依赖：\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n    </dependencies>\r\n启动类启用定时\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\nimport org.springframework.scheduling.annotation.EnableScheduling;\r\n\r\n@EnableScheduling\r\n@SpringBootApplication\r\npublic class StartApplication {\r\n    public static void main(String args[]){\r\n        SpringApplication application = new SpringApplication(StartApplication.class);\r\n        application.run(args);\r\n    }\r\n}\r\n定时任务业务类：\r\npackage com.schedule;\r\n\r\nimport org.springframework.scheduling.annotation.Scheduled;\r\nimport org.springframework.stereotype.Component;\r\n\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.Date;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\n\r\n@Component\r\npublic class ScheduleTask {\r\n\r\n    private static final SimpleDateFormat format = new SimpleDateFormat(\"HH:mm:ss\");\r\n\r\n    private AtomicInteger count = new AtomicInteger();\r\n\r\n    @Scheduled(fixedRate = 6000)\r\n    public void  reportTime(){\r\n        System.out.println(\"现在的时间是：\"+format.format(new Date()));\r\n    }\r\n\r\n    /**\r\n     * 以固定的频率去执行任务\r\n     */\r\n    @Scheduled(initialDelay = 10000,fixedRate = 3000)\r\n    public void  reportNumber(){\r\n        System.out.println(count.incrementAndGet());\r\n    }\r\n\r\n    /**\r\n     * 以固定的延时去执行任务\r\n     */\r\n    @Scheduled(initialDelay = 10000,fixedDelay = 3000)\r\n    public void  reportNumberDelay(){\r\n        System.out.println(count.incrementAndGet());\r\n    }\r\n}\r\n\r\n运行结果如下：\r\n\r\n现在的时间是：09:59:57\r\n1\r\n2\r\n现在的时间是：10:00:03\r\n3\r\n4\r\n5\r\n6\r\n现在的时间是：10:00:09\r\n7\r\n使用说明：\r\n@Scheduled(fixedRate = 1000) ：上一次开始执行时间点之后1秒再执行\r\n@Scheduled(fixedDelay = 1000) ：上一次执行完毕时间点之后1秒再执行\r\n@Scheduled(initialDelay=1000, fixedRate=6000) ：第一次延迟1秒后执行，之后按fixedRate的规则每6秒执行一次 @Scheduled(initialDelay=1000, fixedDelay=6000) ：第一次延迟1秒后执行，之后按fixedDelay的规则每6秒执行一次\r\n源码地址', '1', 'post', 'publish', 'springboot', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('7', 'springboot之thymeleaf整合与使用', 'article7', '1546854881', '1547189195', 'springboot之thymeleaf整合与使用\r\n发布于 2018-04-26\r\nThymeleaf的介绍\r\n简单说， Thymeleaf 是一个跟 Velocity、FreeMarker 类似的模板引擎，它可以完全替代 JSP 。相较与其他的模板引擎，它有如下三个极吸引人的特点：\r\n\r\nThymeleaf 在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。这是由于它支持 html 原型，然后在 html 标签里增加额外的属性来达到模板+数据的展示方式。浏览器解释 html 时会忽略未定义的标签属性，所以 thymeleaf 的模板可以静态地运行；当有数据返回到页面时，Thymeleaf 标签会动态地替换掉静态内容，使页面动态显示。\r\n\r\nThymeleaf 开箱即用的特性。它提供标准和spring标准两种方言，可以直接套用模板实现JSTL、 OGNL表达式效果，避免每天套模板、该jstl、改标签的困扰。同时开发人员也可以扩展和创建自定义的方言。\r\n\r\nThymeleaf 提供spring标准方言和一个与 SpringMVC 完美集成的可选模块，可以快速的实现表单绑定、属性编辑器、国际化等功能。\r\n\r\n与springboot的整合\r\n项目构建\r\n先贴出pom文件\r\n\r\n<properties>\r\n        <java.version>1.8</java.version>\r\n        <!-- 替换成3.0版本-->\r\n        <thymeleaf.version>3.0.0.RELEASE</thymeleaf.version>\r\n        <thymeleaf-layout-dialect.version>2.0.0</thymeleaf-layout-dialect.version>\r\n    </properties>\r\n    <packaging>jar</packaging>\r\n\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>1.5.1.RELEASE</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n    <dependencies>\r\n        <!-- spring boot 配置 -->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n        <!-- spring boot 热部署-->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-devtools</artifactId>\r\n            <optional>true</optional>\r\n        </dependency>\r\n    </dependencies>\r\n\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <configuration>\r\n                    <fork>true</fork><!-- fork:如果没有该配置，这个devtools不会起作用，即应用不会restart -->\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n几个注意点：\r\n\r\n这里使用thymeleaf3.0版本，springboot自带的是2.x版本的，灰常不好用，特别是标签的校验，必须是严格的xml格式，标签必须要求闭合，3.0就不会再有校验的烦恼了\r\n热部署，springboot是支持热部署的，主要是靠devtools的依赖，省去每次修改页面再重启的烦恼\r\napplication.properties配置\r\n\r\nserver.port=80\r\n\r\nspring.thymeleaf.encoding=UTF-8\r\nspring.thymeleaf.cache=false\r\nspring.thymeleaf.prefix=classpath:/templates/\r\nspring.thymeleaf.check-template=true\r\nspring.thymeleaf.suffix=.html\r\nspring.thymeleaf.mode=HTML5\r\n几个注意点：\r\n\r\nhtml文件都放在resource目录下的templates文件下\r\n静态资源，比如css，js，都是放在resource目录下的static文件夹下\r\n整合\r\n先先一个实体类，user，有姓名 username，地址 address两个属性\r\n在resource/templates目录下新建一个，index.html，内容如下：\r\n<!DOCTYPE html>\r\n<html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\">\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <title>Title</title>\r\n</head>\r\n<body>\r\n<span th:text=\"${user.address}\"></span>\r\n<p th:text=\"${user.username}\"></p>\r\n</body>\r\n</html>\r\n编写controller类，内容如下：\r\npackage com.controller;\r\n\r\nimport com.domain.UserVo;\r\nimport org.springframework.stereotype.Controller;\r\nimport org.springframework.web.bind.annotation.GetMapping;\r\n\r\nimport javax.servlet.http.HttpServletRequest;\r\n\r\n@Controller\r\npublic class IndexController {\r\n\r\n    @GetMapping(value = \"\")\r\n    public static String index(HttpServletRequest request){\r\n        UserVo userVo = new UserVo();\r\n        userVo.setAddress(\"上海\");\r\n        userVo.setUsername(\"小明\");\r\n        request.setAttribute(\"user\",userVo);\r\n        return \"index\";\r\n    }\r\n}\r\n\r\n最后启动服务，访问: http://127.0.0.1 查看结果。thymeleaf整个完毕\r\n基础语法\r\n获取变量值\r\n<p th:text=\"\'Hello！, \' + ${name} + \'!\'\" >3333</p>\r\n可以看出获取变量值用$符号,对于javaBean的话使用变量名.属性名方式获取,这点和EL表达式一样.\r\n\r\n另外$表达式只能写在th标签内部,不然不会生效,上面例子就是使用th:text标签的值替换p标签里面的值,至于p里面的原有的值只是为了给前端开发时做展示用的.这样的话很好的做到了前后端分离.\r\n\r\n引入URL\r\nThymeleaf对于URL的处理是通过语法@{…}来处理的\r\n\r\n<a th:href=\"@{http://blog.csdn.net/u012706811}\">绝对路径</a>\r\n<a th:href=\"@{/}\">相对路径</a>\r\n<a th:href=\"@{css/bootstrap.min.css}\">Content路径,默认访问static下的css文件夹</a>\r\n类似的标签有:th:href和th:src\r\n\r\n字符串替换\r\n很多时候可能我们只需要对一大段文字中的某一处地方进行替换，可以通过字符串拼接操作完成：\r\n\r\n<span th:text=\"\'Welcome to our application, \' + ${user.name} + \'!\'\">\r\n一种更简洁的方式：\r\n\r\n<span th:text=\"|Welcome to our application, ${user.name}!|\">\r\n当然这种形式限制比较多，|…|中只能包含变量表达式${…}，不能包含其他常量、条件表达式等。\r\n\r\n元素符\r\n在表达式中可以使用各类算术运算符，例如+, -, *, /, %\r\n\r\nth:with=\"isEven=(${prodStat.count} % 2 == 0)\"\r\n逻辑运算符>, <, <=,>=，==,!=都可以使用，唯一需要注意的是使用<,>时需要用它的HTML转义符：\r\n\r\nth:if=\"${prodStat.count} > 1\"\r\nth:text=\"\'Execution mode is \' + ( (${execMode} == \'dev\')? \'Development\' : \'Production\')\"\r\n条件\r\nif/unless Thymeleaf中使用th:if和th:unless属性进行条件判断，下面的例子中，标签只有在th:if中条件成立时才显示：\r\n\r\n<a th:href=\"@{/login}\" th:unless=${session.user != null}>Login</a>\r\nth:unless于th:if恰好相反，只有表达式中的条件不成立，才会显示其内容。\r\n\r\nSwitch Thymeleaf同样支持多路选择Switch结构：\r\n\r\n<div th:switch=\"${user.role}\">\r\n  <p th:case=\"\'admin\'\">User is an administrator</p>\r\n  <p th:case=\"#{roles.manager}\">User is a manager</p>\r\n</div>\r\n默认属性default可以用*表示：\r\n\r\n<div th:switch=\"${user.role}\">\r\n  <p th:case=\"\'admin\'\">User is an administrator</p>\r\n  <p th:case=\"#{roles.manager}\">User is a manager</p>\r\n  <p th:case=\"*\">User is some other thing</p>\r\n</div>\r\n循环\r\n渲染列表数据是一种非常常见的场景，例如现在有n条记录需要渲染成一个表格，该数据集合必须是可以遍历的，使用th:each标签：\r\n\r\n<body>\r\n  <h1>Product list</h1>\r\n\r\n  <table>\r\n    <tr>\r\n      <th>NAME</th>\r\n      <th>PRICE</th>\r\n      <th>IN STOCK</th>\r\n    </tr>\r\n    <tr th:each=\"prod : ${prods}\">\r\n      <td th:text=\"${prod.name}\">Onions</td>\r\n      <td th:text=\"${prod.price}\">2.41</td>\r\n      <td th:text=\"${prod.inStock}? #{true} : #{false}\">yes</td>\r\n    </tr>\r\n  </table>\r\n\r\n  <p>\r\n    <a href=\"../home.html\" th:href=\"@{/}\">Return to home</a>\r\n  </p>\r\n</body>\r\n可以看到，需要在被循环渲染的元素（这里是）中加入th:each标签，其中th:each=”prod : ${prods}”意味着对集合变量prods进行遍历，循环变量是prod在循环体中可以通过表达式访问。', '1', 'post', 'publish', 'springboot,thymeleaf', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('8', 'springboot之邮件的发送', 'article8', '1546854917', '1547609200', 'springboot之邮件的发送\r\n发布于 2018-04-26\r\nSpring boot中对邮件的发送也提供了支持，本篇文章只要是介绍sringboot中如何发送邮件。 如果对springboot很熟悉，那么这个熟悉起来也很快的:scream:。\r\n\r\npom文件\r\n  <properties>\r\n        <java.version>1.8</java.version>\r\n        <thymeleaf.version>3.0.0.RELEASE</thymeleaf.version>\r\n        <thymeleaf-layout-dialect.version>2.0.0</thymeleaf-layout-dialect.version>\r\n    </properties>\r\n    <packaging>jar</packaging>\r\n\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>1.5.1.RELEASE</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n    <dependencies>\r\n\r\n        <!-- spring boot 配置 -->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n        <!-- spring boot 热部署-->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-devtools</artifactId>\r\n            <optional>true</optional>\r\n        </dependency>\r\n\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-mail</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n    </dependencies>\r\n所需要的依赖全都在这里了。\r\n\r\napplication.properties\r\n这个配置文件需要配置一些，发送邮件所需要的配置\r\n\r\nspring.mail.host=smtp.qq.com\r\nspring.mail.port=587\r\nspring.mail.username=xxxxxx\r\nspring.mail.password=xxxxxx\r\n\r\nspring.thymeleaf.cache=false\r\n\r\n推荐使用qq邮箱，163的会频繁报错，抽风。\r\n\r\n发送邮件代码：\r\npackage com.service.impl;\r\n\r\nimport com.service.IMailService;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.beans.factory.annotation.Value;\r\nimport org.springframework.core.io.FileSystemResource;\r\nimport org.springframework.mail.SimpleMailMessage;\r\nimport org.springframework.mail.javamail.JavaMailSender;\r\nimport org.springframework.mail.javamail.MimeMessageHelper;\r\nimport org.springframework.stereotype.Component;\r\nimport org.thymeleaf.TemplateEngine;\r\nimport org.thymeleaf.context.Context;\r\n\r\nimport javax.annotation.Resource;\r\nimport javax.mail.MessagingException;\r\nimport javax.mail.internet.MimeMessage;\r\nimport java.io.File;\r\n\r\n/**\r\n * @author janti\r\n * @date 2018/5/3 22:07\r\n */\r\n@Component\r\npublic class MailServiceImpl implements IMailService{\r\n\r\n    @Autowired\r\n    private JavaMailSender mailSender;\r\n\r\n\r\n    @Resource\r\n    private TemplateEngine templateEngine;\r\n\r\n    @Value(\"${spring.mail.username}\")\r\n    private String mailFrom;\r\n\r\n    /**\r\n     * 发送简单邮件\r\n     *\r\n     * @param to\r\n     * @param subject\r\n     * @param content\r\n     */\r\n    @Override\r\n    public void sendSimpleEmail(String to,String subject,String content) {\r\n        SimpleMailMessage message = new SimpleMailMessage();\r\n        message.setFrom(mailFrom);\r\n        message.setTo(to);\r\n        message.setSubject(subject);\r\n        message.setText(content);\r\n        mailSender.send(message);\r\n    }\r\n\r\n    /**\r\n     * 发送html邮件\r\n     *\r\n     * @param to\r\n     * @param subject\r\n     * @param content\r\n     */\r\n    @Override\r\n    public void sendHtmlMail(String to, String subject, String content) {\r\n        MimeMessage mimeMessage = mailSender.createMimeMessage();\r\n        try {\r\n            //true表示需要创建一个multipart message\r\n            MimeMessageHelper helper = new MimeMessageHelper(mimeMessage,true);\r\n            helper.setFrom(mailFrom);\r\n            helper.setTo(to);\r\n            helper.setSubject(subject);\r\n            helper.setText(content,true);\r\n            mailSender.send(mimeMessage);\r\n        } catch (MessagingException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    /**\r\n     * 发送带附件的邮件\r\n     *\r\n     * @param to\r\n     * @param subject\r\n     * @param content\r\n     * @param filepath\r\n     */\r\n    @Override\r\n    public void sendFileMail(String to, String subject, String content, String filepath) {\r\n        MimeMessage mimeMessage = mailSender.createMimeMessage();\r\n        try {\r\n            MimeMessageHelper helper = new MimeMessageHelper(mimeMessage,true);\r\n            helper.setFrom(mailFrom);\r\n            helper.setTo(to);\r\n            helper.setSubject(subject);\r\n            helper.setText(content,true);\r\n\r\n            FileSystemResource file = new FileSystemResource(new File(filepath));\r\n            String fileName = filepath.substring(filepath.lastIndexOf(File.separator));\r\n            helper.addAttachment(fileName,file);\r\n\r\n            mailSender.send(mimeMessage);\r\n\r\n        }catch (Exception e){\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    /**\r\n     * 使用模板来发送邮件\r\n     *\r\n     * @param to\r\n     * @param subject\r\n     */\r\n    @Override\r\n    public void sendTemplateMail(String to, String subject) {\r\n        Context context = new Context();\r\n        context.setVariable(\"username\",\"jantent\");\r\n        String mailHtml =templateEngine.process(\"mail\",context);\r\n        sendHtmlMail(to,subject,mailHtml);\r\n    }\r\n}\r\n\r\n发送模板邮件\r\n这里使用了thymeleaf作为渲染引擎，通常注册，验证，修改密码之类的可以发送模板邮件\r\n\r\n<!DOCTYPE html>\r\n<html lang=\"zh\" xmlns:th=\"http://www.thymeleaf.org\">\r\n<head>\r\n    <meta charset=\"UTF-8\"/>\r\n    <title>Title</title>\r\n</head>\r\n<body>\r\n<p>用户：</p>\r\n<p th:text=\"${username}\"></p>\r\n<br>您好,这是我的github<br/>\r\n<hr/>\r\n<a  th:href=\"@{ https://github.com/JayTange }\">链接地址</a>\r\n</body>\r\n</html>\r\n代码在这里觉得有用的话 给个star', '1', 'post', 'publish', 'springboot', 'springboot', '', '0', '1', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('9', 'springboot之mybatis的整合与使用', 'article9', '1546854950', '1547189154', 'springboot之mybatis的整合与使用\r\n发布于 2018-04-25\r\n概述\r\n  mybatis框架的优点，就不用多说了，今天这边干货主要讲mybatis的逆向工程，以及springboot的集成技巧，和分页的使用\r\n\r\n  因为在日常的开发中，当碰到特殊需求之类会手动写一下sql语句，大部分的时候完全可以用mybatis的逆向工程替代。\r\n\r\nmybatis逆向工程\r\n相比较而言，代码形式的逆向工程，更加灵活方便，简单，易于管理，而且可以上传到git中存储。而且也只需要简单的三步就能完成自动生成代码。下面介绍如果搭建并生成xml和代码\r\n\r\n第一步：搭建工程\r\n本项目使用的是maven搭建的工程，在你的pom文件中加入以下依赖：（这里以mysql数据库为例）\r\n\r\n        <!-- https://mvnrepository.com/artifact/org.mybatis/mybatis -->\r\n        <dependency>\r\n            <groupId>org.mybatis</groupId>\r\n            <artifactId>mybatis</artifactId>\r\n            <version>3.4.0</version>\r\n        </dependency>\r\n        <!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->\r\n        <dependency>\r\n            <groupId>mysql</groupId>\r\n            <artifactId>mysql-connector-java</artifactId>\r\n            <version>5.1.34</version>\r\n        </dependency>\r\n        <!-- https://mvnrepository.com/artifact/log4j/log4j -->\r\n        <dependency>\r\n            <groupId>log4j</groupId>\r\n            <artifactId>log4j</artifactId>\r\n            <version>1.2.17</version>\r\n        </dependency>\r\n        <!-- https://mvnrepository.com/artifact/org.mybatis.generator/mybatis-generator-core -->\r\n        <dependency>\r\n            <groupId>org.mybatis.generator</groupId>\r\n            <artifactId>mybatis-generator-core</artifactId>\r\n            <version>1.3.5</version>\r\n        </dependency>\r\n    </dependencies>\r\n第二步：配置generatorConfig.xml\r\n该xml文件是mybatis的配置项 这里记录了数据库连接的配置，\r\n\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<!DOCTYPE generatorConfiguration\r\n        PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\"\r\n        \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\">\r\n\r\n<generatorConfiguration>\r\n    <context id=\"testTables\" targetRuntime=\"MyBatis3\">\r\n        <commentGenerator>\r\n            <!-- 是否去除自动生成的注释 true：是 ： false:否 -->\r\n            <property name=\"suppressAllComments\" value=\"true\" />\r\n        </commentGenerator>\r\n        <!--数据库连接的信息：驱动类、连接地址、用户名、密码 -->\r\n        <jdbcConnection driverClass=\"com.mysql.jdbc.Driver\"\r\n                        connectionURL=\"jdbc:mysql://localhost:3306/database\" userId=\"root\"\r\n                        password=\"123456\">\r\n        </jdbcConnection>\r\n\r\n        <!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL和NUMERIC类型解析为java.math.BigDecimal -->\r\n        <javaTypeResolver>\r\n            <property name=\"forceBigDecimals\" value=\"false\" />\r\n        </javaTypeResolver>\r\n\r\n        <!-- targetProject:生成PO类的位置，重要！！ -->\r\n        <javaModelGenerator targetPackage=\"springboot.modal.vo\"\r\n                            targetProject=\".\\src\">\r\n            <!-- enableSubPackages:是否让schema作为包的后缀 -->\r\n            <property name=\"enableSubPackages\" value=\"false\" />\r\n            <!-- 从数据库返回的值被清理前后的空格 -->\r\n            <property name=\"trimStrings\" value=\"true\" />\r\n        </javaModelGenerator>\r\n        <!-- targetProject:mapper映射文件生成的位置，重要！！ -->\r\n        <sqlMapGenerator targetPackage=\"springboot.dao\"\r\n                         targetProject=\".\\src\">\r\n            <property name=\"enableSubPackages\" value=\"false\" />\r\n        </sqlMapGenerator>\r\n        <!-- targetPackage：mapper接口生成的位置，重要！！ -->\r\n        <javaClientGenerator type=\"XMLMAPPER\"\r\n                             targetPackage=\"springboot.dao\"\r\n                             targetProject=\".\\src\">\r\n            <property name=\"enableSubPackages\" value=\"false\" />\r\n        </javaClientGenerator>\r\n        <!-- 指定数据库表，要生成哪些表，就写哪些表，要和数据库中对应，不能写错！ -->\r\n        <table tableName=\"t_contents\" domainObjectName=\"ContentVo\" mapperName=\"ContentVoMapper\" ></table>\r\n\r\n    </context>\r\n</generatorConfiguration>\r\n第三步：启动类\r\n启动类主要设置main方法以及，制定配置文件generatorConfig.xml的路径\r\n\r\nimport org.mybatis.generator.api.MyBatisGenerator;\r\nimport org.mybatis.generator.config.Configuration;\r\nimport org.mybatis.generator.config.xml.ConfigurationParser;\r\nimport org.mybatis.generator.internal.DefaultShellCallback;\r\n\r\nimport java.io.File;\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\n\r\n\r\npublic class Generator {\r\n    public static void main(String args[]) throws  Exception{\r\n        List<String> warnings = new ArrayList<String>();\r\n        boolean overwrite  = true;\r\n        File configFile = new File(\"./src/main/resources/generatorconfig.xml\");\r\n        System.out.println(configFile.exists());\r\n        ConfigurationParser cp = new ConfigurationParser(warnings);\r\n        Configuration config = cp.parseConfiguration(configFile);\r\n        DefaultShellCallback callback = new DefaultShellCallback(overwrite);\r\n        MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings);\r\n        myBatisGenerator.generate(null);\r\n    }\r\n}\r\n当然如果有你想要设置日志输出的话，可以加一个log4j.properties,简单配置一下日志输出：\r\n\r\n# Global logging configuration\r\nlog4j.rootLogger=DEBUG, stdout\r\n# MyBatis logging configuration...\r\nlog4j.logger.org.mybatis.example.BlogMapper=TRACE\r\n# Console output...\r\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\r\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\r\nlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n\r\n最后运行启动类Generator，运行之前得确保，在数据库中先创建好表\r\n\r\n工程已经搭建好了，可以参考github上： mybatis逆向工程GitHub\r\n\r\n逆向工程如何使用\r\nmapper中的方法\r\n逆向工程生成完毕后，mybatis会在mapper中提供一些默认的接口和参数，下面就介绍一下这些方法的使用：\r\n\r\n方法	功能说明\r\nint countByExample(UserExample example)	按条件计数\r\nint deleteByPrimaryKey(Integer id)	按主键删除\r\nint deleteByExample(UserExample example)	按条件删除\r\nString/Integer insert(User record)	插入数据，返回值的ID\r\nString/Integer insertSelective(User record)	插入一条数据,只插入不为null的字段\r\nUser selectByPrimaryKey(Integer id)	按主键查询\r\nList selectByExample(UserExample example)	按条件查询\r\nList selectByExampleWithBLOGs(UserExample example)	按条件查询（包括BLOB字段）。只有当数据表中的字段类型有为二进制的才会产生。\r\nint updateByPrimaryKey(User record)	按主键更新\r\nint updateByPrimaryKeySelective(User record)	按主键更新值不为null的字段\r\nint updateByExample(User record, UserExample example)	按条件更新\r\nint updateByExampleSelective(User record, UserExample example)	按条件更新值不为null的字段\r\nexample类中的方法\r\nmybatis的逆向工程中会生成实例及实例对应的example，example用于添加条件，相当where后面的部分\r\n\r\nxxxExample example = new xxxExample();\r\nCriteria criteria = new Example().createCriteria();\r\n下表是常用方法\r\n\r\n方法	说明\r\nexample.setOrderByClause(“字段名 ASC”);	添加升序排列条件，DESC为降序\r\nexample.setDistinct(false)	去除重复，boolean型，true为选择不重复的记录。\r\ncriteria.andXxxIsNull	添加字段xxx为null的条件\r\ncriteria.andXxxIsNotNull	添加字段xxx不为null的条件\r\ncriteria.andXxxNotEqualTo(value)	添加xxx字段不等于value条件\r\ncriteria.andXxxGreaterThan(value)	添加xxx字段大于value条件\r\ncriteria.andXxxGreaterThanOrEqualTo(value)	添加xxx字段大于等于value条件\r\ncriteria.andXxxLessThan(value)	添加xxx字段小于value条件\r\ncriteria.andXxxLessThanOrEqualTo(value)	添加xxx字段小于等于value条件\r\ncriteria.andXxxIn(List<？>)	添加xxx字段值在List<？>条件\r\ncriteria.andXxxNotIn(List<？>)	添加xxx字段值不在List<？>条件\r\ncriteria.andXxxLike(“%”+value+”%”)	添加xxx字段值为value的模糊查询条件\r\ncriteria.andXxxNotLike(“%”+value+”%”)	添加xxx字段值不为value的模糊查询条件\r\ncriteria.andXxxBetween(value1,value2)	添加xxx字段值在value1和value2之间条件\r\ncriteria.andXxxNotBetween(value1,value2)	添加xxx字段值不在value1和value2之间条件\r\nsringboot整合mybatis\r\nspringboot整合mybatis很简单 只需要简单的配置即可以。 这里使用时xml方式，注解方式相对而言是清爽一些，但是sql全都堆砌在java文件中，并不利于阅读，而且也没有xml方式灵活。\r\n\r\n项目构建\r\n这里使用的是maven来构建项目，下面是pom文件：\r\n\r\n  <properties>\r\n        <java.version>1.8</java.version>\r\n    </properties>\r\n\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>1.5.1.RELEASE</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n    <dependencies>\r\n        <!-- 数据库连接池-->\r\n        <dependency>\r\n            <groupId>com.alibaba</groupId>\r\n            <artifactId>druid</artifactId>\r\n            <version>1.0.18</version>\r\n        </dependency>\r\n\r\n        <!-- mysql -->\r\n        <dependency>\r\n            <groupId>mysql</groupId>\r\n            <artifactId>mysql-connector-java</artifactId>\r\n            <version>5.1.35</version>\r\n            <scope>runtime</scope>\r\n        </dependency>\r\n\r\n        <!-- spring boot 配置 -->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-thymeleaf</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n      \r\n        <dependency>\r\n            <groupId>org.mybatis.spring.boot</groupId>\r\n            <artifactId>mybatis-spring-boot-starter</artifactId>\r\n            <version>1.2.0</version>\r\n        </dependency>\r\n    </dependencies>\r\n工程搭建\r\n搭建springboot第一件事就是使用配置application.properties。整合mybatis的时候需要配置jdbc的信息，这里还用了阿里的连接池Druid.下面是详细的配置信息：\r\n\r\nserver.port=80\r\n#spring.datasource.type=com.alibaba.druid.pool.DruidDataSource\r\nspring.datasource.driverClassName=com.mysql.jdbc.Driver\r\nspring.datasource.url=jdbc:mysql://localhost:3306/bootmybatis?useSSL=false&useUnicode=true&characterEncoding=utf-8&autoReconnect=true\r\n#用户名\r\nspring.datasource.username=root\r\n#密码\r\nspring.datasource.password=123456\r\nspring.datasource.initialSize=20\r\nspring.datasource.minIdle=10\r\nspring.datasource.maxActive=100\r\n# 输出mybatis日志 sql语句方便调试\r\nlogging.level.com.dao=DEBUG\r\n下图是工程结构图： alt\r\n\r\n这里的UserVoMapper,UserVo,UserVoExample,都是使用的逆向工程生成的 启动类代码：\r\n\r\npackage com;\r\n\r\nimport com.alibaba.druid.pool.DruidDataSource;\r\nimport org.apache.ibatis.session.SqlSessionFactory;\r\nimport org.mybatis.spring.SqlSessionFactoryBean;\r\nimport org.mybatis.spring.annotation.MapperScan;\r\nimport org.springframework.boot.Banner;\r\nimport org.springframework.boot.SpringApplication;\r\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\r\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\r\nimport org.springframework.boot.context.properties.ConfigurationProperties;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.ComponentScan;\r\nimport org.springframework.core.io.support.PathMatchingResourcePatternResolver;\r\n\r\nimport javax.sql.DataSource;\r\n\r\n@SpringBootApplication\r\n@ComponentScan\r\n@EnableAutoConfiguration\r\n@MapperScan(\"com.dao\")\r\npublic class StartApplication {\r\n    public static void main(String[] args) throws Exception {\r\n        SpringApplication app = new SpringApplication(StartApplication.class);\r\n        app.setBannerMode(Banner.Mode.OFF);\r\n        app.run(args);\r\n    }\r\n\r\n    // datasource注入\r\n    @Bean\r\n    @ConfigurationProperties(prefix = \"spring.datasource\")\r\n    public DataSource dataSource() {\r\n        return new DruidDataSource();\r\n    }\r\n\r\n    //mybatis SQLSession注入\r\n    @Bean\r\n    public SqlSessionFactory sqlSessionFactoryBean() throws Exception {\r\n        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();\r\n        sqlSessionFactoryBean.setDataSource(dataSource());\r\n        PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();\r\n        // 这里设置mybatis xml文件的地址\r\n        sqlSessionFactoryBean.setMapperLocations(resolver.getResources(\"classpath:/mapper/*.xml\"));\r\n        return sqlSessionFactoryBean.getObject();\r\n    }\r\n}\r\n\r\n测试\r\n在IndexController代码如下：\r\n\r\npackage com.controller;\r\n\r\nimport com.dao.UserVoMapper;\r\nimport com.domain.vo.UserVo;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.stereotype.Controller;\r\nimport org.springframework.web.bind.annotation.GetMapping;\r\nimport org.springframework.web.bind.annotation.ResponseBody;\r\n\r\n\r\n@Controller\r\npublic class IndexController {\r\n\r\n    @Autowired\r\n    UserVoMapper userDao;\r\n\r\n    @GetMapping(value = \"\")\r\n    @ResponseBody\r\n    public UserVo index(){\r\n        UserVo userVo = new UserVo();\r\n        userVo.setUsername(\"SELECTIVE\");\r\n        userVo.setPassword(\"123456\");\r\n        userVo.setAddress(\"北京\");\r\n        userDao.insertSelective(userVo);\r\n        userVo = userDao.selectByPrimaryKey(1);\r\n        return userVo;\r\n    }\r\n}\r\n\r\n启动startApplication,在浏览器中输入http://127.0.0.1,即可查看到结果。\r\n\r\n如果有不明白的可以去git上查看源码，传送门 喜欢的话，给个star', '1', 'post', 'publish', 'springboot,mybatis', 'springboot', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('10', '基础巩固-长连接、短连接、心跳机制、断线重连', 'article10', '1546855027', '1546939139', '基础巩固-长连接、短连接、心跳机制、断线重连\r\n发布于 2018-06-13\r\n概述\r\n可承遇到，不知什么原因，一个夜晚，机房中，大片的远程调用连接断开。\r\n\r\n第二天早上，用户访问高峰，大部分服务器都在获取连接，造成大片网络阻塞。\r\n\r\n服务崩溃，惨不忍睹的景象。\r\n\r\n本文将从长连接和短连接的概念切入，再到长连接与短连接的区别，以及应用场景，引出心跳机制和断线重连，给出代码实现。\r\n\r\n从原理到实践杜绝此类现象。\r\n\r\n短连接\r\n概念\r\n\r\nclient与server通过三次握手建立连接，client发送请求消息，server返回响应，一次连接就完成了。\r\n\r\n这时候双方任意都可以发起close操作，不过一般都是client先发起close操作。上述可知，短连接一般只会在 client/server间传递一次请求操作。\r\n\r\n短连接的优缺点\r\n\r\n管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。\r\n\r\n使用场景\r\n\r\n通常浏览器访问服务器的时候就是短连接。\r\n\r\n对于服务端来说，长连接会耗费服务端的资源，而且用户用浏览器访问服务端相对而言不是很频繁的\r\n\r\n如果有几十万，上百万的连接，服务端的压力会非常大，甚至会崩溃。\r\n\r\n所以对于并发量大，请求频率低的，建议使用短连接。\r\n\r\n长连接\r\n什么是长连接\r\n\r\nclient向server发起连接，server接受client连接，双方建立连接。\r\n\r\nClient与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。\r\n\r\n长连接的生命周期\r\n\r\n正常情况下，一条TCP长连接建立后，只要双不提出关闭请求并且不出现异常情况，这条连接是一直存在的.\r\n\r\n操作系统不会自动去关闭它，甚至经过物理网络拓扑的改变之后仍然可以使用。\r\n\r\n所以一条连接保持几天、几个月、几年或者更长时间都有可能，只要不出现异常情况或由用户（应用层）主动关闭。\r\n\r\n客户端和服务单可一直使用该连接进行数据通信。\r\n\r\n长连接的优点\r\n\r\n长连接可以省去较多的TCP建立和关闭的操作，减少网络阻塞的影响，\r\n\r\n当发生错误时，可以在不关闭连接的情况下进行提示，\r\n\r\n减少CPU及内存的使用，因为不需要经常的建立及关闭连接。\r\n\r\n长连接的缺点\r\n\r\n连接数过多时，影响服务端的性能和并发数量。\r\n\r\n使用场景\r\n\r\n数据库的连接就是采用TCP长连接.\r\n\r\nRPC，远程服务调用，在服务器，一个服务进程频繁调用另一个服务进程，可使用长连接，减少连接花费的时间。\r\n\r\n总结\r\n\r\n1.对于长连接和短连接的使用是需要根据应用场景来判断的\r\n\r\n2.长连接并不是万能的，也是需要维护的，\r\n\r\n长连接的实现\r\n心跳机制\r\n\r\n应用层协议大多都有HeartBeat机制，通常是客户端每隔一小段时间向服务器发送一个数据包，通知服务器自己仍然在线。\r\n\r\n并传输一些可能必要的数据。使用心跳包的典型协议是IM，比如QQ/MSN/飞信等协议。\r\n\r\n在TCP的机制里面，本身是存在有心跳包的机制的，也就是TCP的选项：SO_KEEPALIVE。\r\n\r\n系统默认是设置的2小时的心跳频率。但是它检查不到机器断电、网线拔出、防火墙这些断线。\r\n\r\n而且逻辑层处理断线可能也不是那么好处理。一般，如果只是用于保活还是可以的。 为什么需要心跳机制？\r\n\r\n因为网络的不可靠性, 有可能在 TCP 保持长连接的过程中, 由于某些突发情况, 例如网线被拔出, 突然掉电等,\r\n\r\n会造成服务器和客户端的连接中断. 在这些突发情况下, 如果恰好服务器和客户端之间没有交互的话, 那么它们是不能在短时间内发现对方已经掉线的.\r\n\r\n心跳机制即可解决此类问题。 TCP协议的KeepAlive机制\r\n\r\n默认KeepAlive状态是不打开的。\r\n\r\n需要将setsockopt将SOL_SOCKET.SO_KEEPALIVE设置为1才是打开KeepAlive状态，\r\n\r\n并且可以设置三个参数：\r\n\r\ntcp_keepalive_time ，tcp_keepalive_probes ， tcp_keepalive_intvl，\r\n\r\n分别表示：连接闲置多久开始发keepalive的ack包、发几个ack包不回复才当对方已断线、两个ack包之间的间隔。\r\n\r\n很多网络设备，尤其是NAT路由器，由于其硬件的限制（例如内存、CPU处理能力），无法保持其上的所有连接，因此在必要的时候，会在连接池中选择一些不活跃的连接踢掉。\r\n\r\n典型做法是LRU，把最久没有数据的连接给T掉。\r\n\r\n通过使用TCP的KeepAlive机制（修改那个time参数），可以让连接每隔一小段时间就产生一些ack包，以降低被踢掉的风险，当然，这样的代价是额外的网络和CPU负担。 如何实现心跳机制？\r\n\r\n两种方式实现心跳机制:\r\n\r\n使用 TCP 协议层面的 keepalive 机制.\r\n\r\n在应用层上实现自定义的心跳机制.\r\n虽然在 TCP 协议层面上, 提供了 keepalive 保活机制, 但是使用它有几个缺点:\r\n\r\n它不是 TCP 的标准协议, 并且是默认关闭的.\r\n\r\nTCP keepalive 机制依赖于操作系统的实现, 默认的 keepalive 心跳时间是 两个小时, 并且对 keepalive 的修改需要系统调用(或者修改系统配置), 灵活性不够.\r\n\r\nTCP keepalive 与 TCP 协议绑定, 因此如果需要更换为 UDP 协议时, keepalive 机制就失效了.\r\n使用 TCP 层面的 keepalive 机制比自定义的应用层心跳机制节省流量,\r\n\r\n本文的主要介绍应用层方面实现心跳机制，使用netty实现心跳和断线重连。\r\n\r\nnetty实现心跳机制\r\nnetty对心跳机制提供了机制，实现的关键是IdleStateHandler先来看一下他的构造函数\r\n\r\npublic IdleStateHandler(\r\n            long readerIdleTime, long writerIdleTime, long allIdleTime,\r\n            TimeUnit unit) {\r\n        this(false, readerIdleTime, writerIdleTime, allIdleTime, unit);\r\n    }\r\n实例化一个 IdleStateHandler 需要提供三个参数:\r\n\r\nreaderIdleTimeSeconds, 读超时. 即当在指定的时间间隔内没有从 Channel 读取到数据时, 会触发一个 READER_IDLE 的 IdleStateEvent 事件.\r\n\r\nwriterIdleTimeSeconds, 写超时. 即当在指定的时间间隔内没有数据写入到 Channel 时, 会触发一个 WRITER_IDLE 的 IdleStateEvent 事件.\r\n\r\nallIdleTimeSeconds, 读和写都超时. 即当在指定的时间间隔内没有读并且写操作时, 会触发一个 ALL_IDLE 的 IdleStateEvent 事件.\r\n\r\nnetty心跳流程\r\n1.客户端成功连接服务端。\r\n\r\n2.在客户端中的ChannelPipeline中加入IdleStateHandler，设置写事件触发事件为5s.\r\n\r\n3.客户端超过5s未写数据，触发写事件，向服务端发送心跳包，\r\n\r\n4.同样，服务端要对心跳包做出响应，其实给客户端最好的回复就是“不回复”，减轻服务端的压力\r\n\r\n5.超过三次，1过0s服务端都会收到来自客户端的心跳信息，服务端可以认为客户端挂了，可以close链路。\r\n\r\n6.客户端恢复正常，发现链路已断，重新连接服务端。\r\n\r\n代码实现\r\npackage com.heartbreak.server;\r\n\r\nimport io.netty.channel.ChannelHandlerContext;\r\nimport io.netty.channel.SimpleChannelInboundHandler;\r\nimport io.netty.handler.timeout.IdleState;\r\nimport io.netty.handler.timeout.IdleStateEvent;\r\n\r\nimport java.util.Random;\r\n\r\n/**\r\n * @author janti\r\n * @date 2018/6/10 12:21\r\n */\r\npublic class HeartbeatServerHandler extends SimpleChannelInboundHandler<String> {\r\n    // 失败计数器：未收到client端发送的ping请求\r\n    private int unRecPingTimes = 0;\r\n\r\n    // 定义服务端没有收到心跳消息的最大次数\r\n    private static final int MAX_UN_REC_PING_TIMES = 3;\r\n\r\n    private Random random = new Random(System.currentTimeMillis());\r\n\r\n    @Override\r\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\r\n        if (msg!=null && msg.equals(\"Heartbeat\")){\r\n            System.out.println(\"客户端\"+ctx.channel().remoteAddress()+\"--心跳信息--\");\r\n        }else {\r\n            System.out.println(\"客户端----请求消息----：\"+msg);\r\n            String resp = \"商品的价格是：\"+random.nextInt(1000);\r\n            ctx.writeAndFlush(resp);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\r\n        if (evt instanceof IdleStateEvent) {\r\n            IdleStateEvent event = (IdleStateEvent) evt;\r\n            if (event.state()==IdleState.READER_IDLE){\r\n                System.out.println(\"===服务端===(READER_IDLE 读超时)\");\r\n                // 失败计数器次数大于等于3次的时候，关闭链接，等待client重连\r\n                if (unRecPingTimes >= MAX_UN_REC_PING_TIMES) {\r\n                    System.out.println(\"===服务端===(读超时，关闭chanel)\");\r\n                    // 连续超过N次未收到client的ping消息，那么关闭该通道，等待client重连\r\n                    ctx.close();\r\n                } else {\r\n                    // 失败计数器加1\r\n                    unRecPingTimes++;\r\n                }\r\n            }else {\r\n                super.userEventTriggered(ctx,evt);\r\n            }\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\r\n        super.channelActive(ctx);\r\n        System.out.println(\"一个客户端已连接\");\r\n    }\r\n\r\n    @Override\r\n    public void channelInactive(ChannelHandlerContext ctx) throws Exception {\r\n        super.channelInactive(ctx);\r\n        System.out.println(\"一个客户端已断开连接\");\r\n    }\r\n}\r\n服务端server:\r\n\r\npackage com.heartbreak.server;\r\n\r\nimport io.netty.bootstrap.ServerBootstrap;\r\nimport io.netty.channel.*;\r\nimport io.netty.channel.nio.NioEventLoopGroup;\r\nimport io.netty.channel.socket.SocketChannel;\r\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\r\nimport io.netty.handler.codec.string.StringDecoder;\r\nimport io.netty.handler.codec.string.StringEncoder;\r\nimport io.netty.handler.timeout.IdleStateHandler;\r\n\r\nimport java.util.concurrent.TimeUnit;\r\n\r\n/**\r\n * @author tangj\r\n * @date 2018/6/10 10:46\r\n */\r\npublic class HeartBeatServer {\r\n    private static int port = 9817;\r\n\r\n    public HeartBeatServer(int port) {\r\n        this.port = port;\r\n    }\r\n\r\n    ServerBootstrap bootstrap = null;\r\n    ChannelFuture f;\r\n\r\n    // 检测chanel是否接受过心跳数据时间间隔（单位秒）\r\n    private static final int READ_WAIT_SECONDS = 10;\r\n\r\n    public static void main(String args[]) {\r\n        HeartBeatServer heartBeatServer = new HeartBeatServer(port);\r\n        heartBeatServer.startServer();\r\n    }\r\n\r\n    public void startServer() {\r\n        EventLoopGroup bossgroup = new NioEventLoopGroup();\r\n        EventLoopGroup workergroup = new NioEventLoopGroup();\r\n        try {\r\n            bootstrap = new ServerBootstrap();\r\n            bootstrap.group(bossgroup, workergroup)\r\n                    .channel(NioServerSocketChannel.class)\r\n                    .childHandler(new HeartBeatServerInitializer());\r\n            // 服务器绑定端口监听\r\n            f = bootstrap.bind(port).sync();\r\n            System.out.println(\"server start ,port: \"+port);\r\n            // 监听服务器关闭监听，此方法会阻塞\r\n            f.channel().closeFuture().sync();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            bossgroup.shutdownGracefully();\r\n            workergroup.shutdownGracefully();\r\n        }\r\n    }\r\n\r\n\r\n    private class HeartBeatServerInitializer extends ChannelInitializer<SocketChannel> {\r\n\r\n        @Override\r\n        protected void initChannel(SocketChannel ch) throws Exception {\r\n            ChannelPipeline pipeline = ch.pipeline();\r\n            // 监听读操作,读超时时间为5秒，超过5秒关闭channel;\r\n            pipeline.addLast(\"ping\", new IdleStateHandler(READ_WAIT_SECONDS, 0, 0, TimeUnit.SECONDS));\r\n            pipeline.addLast(\"decoder\", new StringDecoder());\r\n            pipeline.addLast(\"encoder\", new StringEncoder());\r\n\r\n            pipeline.addLast(\"handler\", new HeartbeatServerHandler());\r\n        }\r\n    }\r\n\r\n}\r\n客户端handler\r\n\r\npackage com.heartbreak.client;\r\n\r\nimport io.netty.buffer.ByteBuf;\r\nimport io.netty.buffer.Unpooled;\r\nimport io.netty.channel.ChannelHandlerContext;\r\nimport io.netty.channel.EventLoop;\r\nimport io.netty.channel.SimpleChannelInboundHandler;\r\nimport io.netty.handler.timeout.IdleState;\r\nimport io.netty.handler.timeout.IdleStateEvent;\r\nimport io.netty.util.CharsetUtil;\r\nimport io.netty.util.ReferenceCountUtil;\r\n\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.Date;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\n/**\r\n * @author tangj\r\n * @date 2018/6/11 22:55\r\n */\r\npublic class HeartBeatClientHandler extends SimpleChannelInboundHandler<String>{\r\n    private HeartBeatClient client;\r\n\r\n    private SimpleDateFormat format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:dd\");\r\n\r\n    private static final ByteBuf HEARTBEAT_SEQUENCE = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(\"Heartbeat\",\r\n            CharsetUtil.UTF_8));\r\n\r\n    public HeartBeatClientHandler(HeartBeatClient client) {\r\n        this.client = client;\r\n    }\r\n    @Override\r\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\r\n        System.out.println(\"收到服务端回复：\"+msg);\r\n        if (msg.equals(\"Heartbeat\")) {\r\n            ctx.write(\"has read message from server\");\r\n            ctx.flush();\r\n        }\r\n        ReferenceCountUtil.release(msg);\r\n    }\r\n\r\n    @Override\r\n    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\r\n        if (evt instanceof IdleStateEvent) {\r\n            IdleState state = ((IdleStateEvent) evt).state();\r\n            if (state == IdleState.WRITER_IDLE) {\r\n                ctx.writeAndFlush(HEARTBEAT_SEQUENCE.duplicate());\r\n            }\r\n        } else {\r\n            super.userEventTriggered(ctx, evt);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public void channelInactive(ChannelHandlerContext ctx) throws Exception {\r\n        super.channelInactive(ctx);\r\n        System.err.println(\"客户端与服务端断开连接,断开的时间为：\"+format.format(new Date()));\r\n        // 定时线程 断线重连\r\n        final EventLoop eventLoop = ctx.channel().eventLoop();\r\n        eventLoop.schedule(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                client.doConncet();\r\n            }\r\n        }, 10, TimeUnit.SECONDS);\r\n    }\r\n\r\n\r\n}\r\n客户端启动：\r\n\r\npackage com.heartbreak.client;\r\n\r\nimport io.netty.bootstrap.Bootstrap;\r\nimport io.netty.buffer.ByteBuf;\r\nimport io.netty.channel.*;\r\nimport io.netty.channel.nio.NioEventLoopGroup;\r\nimport io.netty.channel.socket.SocketChannel;\r\nimport io.netty.channel.socket.nio.NioSocketChannel;\r\nimport io.netty.handler.codec.string.StringDecoder;\r\nimport io.netty.handler.codec.string.StringEncoder;\r\nimport io.netty.handler.timeout.IdleStateHandler;\r\n\r\nimport java.io.BufferedReader;\r\nimport java.io.InputStreamReader;\r\nimport java.util.Random;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\n/**\r\n * @author tangj\r\n * @date 2018/6/10 16:18\r\n */\r\npublic class HeartBeatClient {\r\n\r\n    private Random random = new Random();\r\n    public Channel channel;\r\n    public Bootstrap bootstrap;\r\n\r\n    protected String host = \"127.0.0.1\";\r\n    protected int port = 9817;\r\n\r\n    public static void main(String args[]) throws Exception {\r\n        HeartBeatClient client = new HeartBeatClient();\r\n        client.run();\r\n        client.sendData();\r\n\r\n    }\r\n\r\n    public void run() throws Exception {\r\n        EventLoopGroup group = new NioEventLoopGroup();\r\n        try {\r\n            bootstrap = new Bootstrap();\r\n            bootstrap.group(group)\r\n                    .channel(NioSocketChannel.class)\r\n                    .handler(new SimpleClientInitializer(HeartBeatClient.this));\r\n            doConncet();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    /**\r\n     * 发送数据\r\n     * @throws Exception\r\n     */\r\n    public void sendData() throws Exception {\r\n        BufferedReader in = new BufferedReader(new InputStreamReader(System.in));\r\n        while (true){\r\n            String cmd = in.readLine();\r\n            switch (cmd){\r\n                case \"close\" :\r\n                    channel.close();\r\n                    break;\r\n                default:\r\n                channel.writeAndFlush(in.readLine());\r\n                    break;\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * 连接服务端\r\n     */\r\n    public void doConncet() {\r\n        if (channel != null && channel.isActive()) {\r\n            return;\r\n        }\r\n        ChannelFuture channelFuture = bootstrap.connect(host, port);\r\n        channelFuture.addListener(new ChannelFutureListener() {\r\n            @Override\r\n            public void operationComplete(ChannelFuture futureListener) throws Exception {\r\n                if (channelFuture.isSuccess()) {\r\n                    channel = futureListener.channel();\r\n                    System.out.println(\"connect server successfully\");\r\n                } else {\r\n                    System.out.println(\"Failed to connect to server, try connect after 10s\");\r\n                    futureListener.channel().eventLoop().schedule(new Runnable() {\r\n                        @Override\r\n                        public void run() {\r\n                            doConncet();\r\n                        }\r\n                    }, 10, TimeUnit.SECONDS);\r\n                }\r\n            }\r\n        });\r\n\r\n    }\r\n\r\n\r\n    private class SimpleClientInitializer extends ChannelInitializer<SocketChannel> {\r\n\r\n        private HeartBeatClient client;\r\n\r\n        public SimpleClientInitializer(HeartBeatClient client) {\r\n            this.client = client;\r\n        }\r\n\r\n        @Override\r\n        protected void initChannel(SocketChannel socketChannel) throws Exception {\r\n            ChannelPipeline pipeline = socketChannel.pipeline();\r\n            pipeline.addLast(new IdleStateHandler(0, 5, 0));\r\n            pipeline.addLast(\"encoder\", new StringEncoder());\r\n            pipeline.addLast(\"decoder\", new StringDecoder());\r\n            pipeline.addLast(\"handler\", new HeartBeatClientHandler(client));\r\n        }\r\n    }\r\n\r\n\r\n}\r\n运行结果：\r\n\r\n1.客户端长时间未发送心跳包，服务端关闭连接 复制代码\r\n\r\nserver start ,port: 9817 一个客户端已连接 ===服务端===(READER_IDLE 读超时) ===服务端===(READER_IDLE 读超时) ===服务端===(READER_IDLE 读超时) ===服务端===(READER_IDLE 读超时) ===服务端===(读超时，关闭chanel) 一个客户端已断开连接\r\n\r\n复制代码\r\n\r\n2.客户端发送心跳包，服务端和客户端保持心跳信息\r\n\r\n一个客户端已连接 客户端/127.0.0.1:55436--心跳信息-- 客户端/127.0.0.1:55436--心跳信息-- 客户端/127.0.0.1:55436--心跳信息-- 客户端/127.0.0.1:55436--心跳信息--\r\n\r\n3.服务单宕机，断开连接，客户端进行重连\r\n\r\n客户端与服务端断开连接,断开的时间为：2018-06-12 23:47:12 Failed to connect to server, try connect after 10s Failed to connect to server, try connect after 10s Failed to connect to server, try connect after 10s connect server successfully\r\n\r\n代码地址：\r\n\r\nLearnTCP', '1', 'post', 'publish', '计算机网络', '计算机网络', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('11', 'kafka学习笔记——基本概念与安装', 'article11', '1546855077', '1546939119', 'kafka学习笔记——基本概念与安装\r\n发布于 2018-07-29\r\n\r\n\r\nKafka是一个开源的，轻量级的、分布式的、具有复制备份、基于zooKeeper协调管理的分布式消息系统。\r\n\r\n它具备以下三个特性：\r\n\r\n能够发布订阅流数据：\r\n\r\n存储流数据时，提供相应的容错机制\r\n\r\n当流数据到达时，能够被及时处理。\r\n\r\n\r\n\r\n下载安装\r\n本次安装只介绍在linux环境下，windows的暂时不考虑。\r\n\r\n下载\r\n作为一个消息中间件，kafka并不是一个jar包，而是一个完整的应用，所以直接取官网下载部署包.\r\n\r\n下载地址：https://kafka.apache.org/downloads\r\n\r\n这里选择：\r\n\r\n下载完毕之后，可以使用winSCP上传到服务器中。\r\n\r\n也可以使用wget命令，直接下载：\r\n\r\n\r\n\r\nwget http://mirrors.shuosc.org/apache/kafka/1.1.1/kafka_2.11-1.1.1.tgz\r\n配置\r\n下载完安装包之后，把它放在/usr/local\r\n\r\n\r\n1  tar -zxf kafka_2.11-1.1.1.tgz \r\n2  mv kafka_2.11-1.1.1.tgz kafka\r\n\r\n换个目录名称，kafka看起来更简洁一些。\r\n\r\n\r\n启动服务\r\nkafka是依赖于zookeeper的，所以再启动kafka之前需要先启动zookeeper。\r\n\r\n之前看到某书，书中说是要再去下载一个zookeeper，其实是没必要的，kafka部署包中本身就有zookeeper。\r\n\r\n首先进入kafka目录\r\n\r\n\r\ncd /usr/local/kakfa\r\n启动zookeeper：\r\n\r\n\r\nbin/zookeeper-server-start.sh -daemon config/zookeeper.properties\r\n执行完命令后使用jps命令查看是否启动：\r\n\r\n1 [root@izbp18twqnsvndjvj1mnagz kafka]# jps \r\n2 9088 app.jar \r\n3 25170 Jps \r\n4 24539 QuorumPeerMain\r\n看到有QuorumPeerMain，说明zookeeper启动成功了。\r\n\r\n启动kafka：\r\n\r\n\r\nbin/kafka-server-start.sh -daemon config/server.properties\r\n当然，你也可以去掉 -daemon，这样就不会kafka占用控制台了。\r\n还是使用jps命令查看运行是否启动成功：\r\n\r\n\r\n\r\n\r\n现在已经完成了helloWorld的第一步，接下来，就了解一下kafka的基本概念，进行验证。\r\n\r\nKafka中几个关键概念\r\nKafka的使用场景：\r\n\r\n1.构建实时的数据流管道，系统和应用程序能够可靠的获取消息。\r\n\r\n2.构建转换或响应数据流的实时流应用程序.\r\n\r\n基本概念：\r\n\r\n1.Kafka是以集群的方式运行在一个或多个数据中心的服务器上的\r\n\r\n2.Kafka引入了主题的概念，它是以主题来分类消息流的\r\n\r\n3.每一条消息都有三部分组成，键，值，时间戳。\r\n\r\n主题（Topic）\r\n主题就是一个分类，或者说一个集合，用来将发布到kafka的消息进行归类。\r\n\r\n通常来说，在Kafka中，一个主题通常有多个用户来订阅和生产消息。\r\n\r\n在实际生产中，在Kafka中都是有多个主题的，对于每个主题，都维护多个分区（partition）日志，如下图所示：\r\n\r\n\r\n\r\n创建主题\r\n创建主题使用kafka-topic.sh脚本，创建单分区单副本的topic test：\r\n\r\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test  \r\n查看主题：\r\n\r\nbin/kafka-topics.sh --list --zookeeper localhost:2181  \r\n输出结果为：\r\n\r\n\r\n\r\n分区（partition）\r\n在主题中，每个分区都是一个有序的、不可变的记录序列，并不断地附加到一个结构化的提交日志中。\r\n\r\n分区中的记录序列都被分配了一个偏移值，该偏移量惟一地标识分区中的每个记录。\r\n\r\n这个偏移值可以是自增的，也可以是开发者自己指定。\r\n\r\n在日志服务器中设置分区有以下几个好处：\r\n\r\n首先，kafka集群允许日志消息扩展到适合的单个服务器的消息，每个分区都会有承载它大小的服务器，一个主题有多个分区，它可以处理任意数量的数据\r\n\r\n其次，消息是并行的，可以同时处理.\r\n\r\n分区的分布式\r\n\r\n在kafka集群中，日志的分区是分布在每个主机上的，每个主机都共享数据和共同处理数据。\r\n\r\n每个分区在集群中的服务器中进行复制，借此实现容错的功能。\r\n\r\n与zookeeper类似，在集群中，总有一个主机扮演leader的角色，其他主机扮演follwers的角色。\r\n\r\n当leader进行读和写操作时，follwers也将重复leader的操作，进行读和写。\r\n\r\n遇到leader故障怎么办，那么其他follwers中的任意一台主机就会自动成为新的leader。\r\n\r\n生产者（producers）\r\n生产者，顾名思义，生产消息。生产者，选择kakfa中的某个主题某个分区进行推送消息。\r\n\r\n为了负载均衡，也可以通过循环的方式来发送消息。\r\n\r\n消费者（consumers）\r\n消费者通常是以组的形式存在，消费者组订阅消息，并且分发给组中的每一个消费者实例。\r\n\r\n消费者实例，可以分布在不同的进程中，也可是不同的机器中。\r\n\r\n如果所有消费者都有相同的组，那么消息将会在消费者组中进行负载均衡分发。\r\n\r\n如果所有消费者上都使用了不同的消费者，那么每个消息都将被广播到消费者实例。\r\n\r\n\r\n\r\n如下图：\r\n\r\n\r\n\r\n有两个kafka集群，这两个集群有四个分区，和两个消费者组。消费者组A有2个消费者实例，消费者组B有四个消费者实例。\r\n\r\n通常来说，主题（topic）都会有少量的消费者组，主题中的一个逻辑（也可以说一个业务）对应着一个消费者组。\r\n\r\n每个消费者组组都由许多消费者实例组成，从而保证可扩展性和容错性。\r\n\r\n\r\n\r\nkafka只记录了所有分区的总数，并不单独记录每个主题中分区的总数。对于大多数应该程序来说，对分区的读写只需要根据分区的偏移值就能找到了。\r\n\r\n\r\n\r\n保障\r\n当消息发送到一个特定的主题分区中，消息的顺序按照其发送的顺序，比如先发送M1，后发送M2，那么M2就排在M1的后面。\r\n当消费者订阅消息时，它获取消息的顺序是按照消息存储的顺序。\r\n假设一个主题，他的容错因子是N（当它为leader时，有N个follwers），该集群最多能允许N-1个follwers 操作失败。\r\n\r\n\r\nKafka的优势\r\n多个生产者\r\nKafka可无缝支持多个生产者，不管客户端使用单个主题还是多个主题。所以它适合从多个系统中收集数据，并以统一的格式对外提供数据。\r\n\r\n多个消费者\r\nKafka支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响。这与其他队列系统不同，其他队列系统消息一旦被一个客户端读取，其他客户端就无法读取它。\r\n\r\n除此之外，消费者可以组成一个群组，消费组可以共享消息流，并保证整个群组对每个给定的消息只处理一次。\r\n\r\n消息持久化\r\n消费者可以非实时的读取消息，这是因为kafka可以将消息存在磁盘中，根据设置的规则进行保存，而且每个主题可以设置单独的保留规则。\r\n\r\n当消费者因为处理速度慢或者突然的流量暴增导致的无法及时的处理消息，那么就可以将消息进行持久化存储，并保证消息不会丢失。\r\n\r\n消费者可以被关闭，但是消息被继续保留在Kafka中，消费者可以从上次中断的地方继续读取消息。\r\n\r\n高性能与伸缩性\r\n一个服务器可称为一个broker，开发时可以是一个，然后扩展成3个，小型集群，随着数据不断增长，可以扩展至上百个。\r\n\r\n对于在线集群进行扩展，丝毫不影响系统的可用性。\r\n\r\n在处理大数据时，Kafka能保证亚秒级别的消息延迟。\r\n\r\n\r\n\r\n总结\r\nkafka是高性能，吞吐量极高的消息中间件。学习kafka需要先去学习它其中的一些概念，只有理解了这些概念，\r\n\r\n才能够在实际生产过程中更好的合理的使用kafka，本文是开篇，主要介绍了一些kafka的概念，下一篇主要内容是kafka的常用api。', '1', 'post', 'publish', 'kafka', 'kafka', '', '0', '1', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('12', '玩转kafka中的生产者', 'article12', '1546855122', '1546939108', '玩转kafka中的生产者\r\n发布于 2018-07-30\r\n上篇文章学习kafka的基本安装和基础概念，本文主要是学习kafka的常用API。其中包括生产者和消费者，\r\n\r\n多线程生产者，多线程消费者，自定义分区等，当然还包括一些避坑指南。\r\n\r\n\r\n\r\n准备工作\r\nkafka版本：2.11-1.1.1\r\n\r\n操作系统：centos7\r\n\r\njava：jdk1.8\r\n\r\n有了以上这些条件就OK了，具体怎么安装和启动Kafka这里就不强调了，可以看上一篇文章。\r\n\r\n新建一个maven工程，需要的依赖如下：\r\n\r\n<dependency>\r\n    <groupId>org.apache.kafka</groupId>\r\n    <artifactId>kafka_2.11</artifactId>\r\n    <version>1.1.1</version>\r\n</dependency>\r\n\r\n<dependency>\r\n    <groupId>org.apache.kafka</groupId>\r\n    <artifactId>kafka-clients</artifactId>\r\n    <version>1.1.1</version>\r\n</dependency>\r\n\r\n\r\n主题管理\r\nkafka的核心就是主题，学会使用kafka的脚本创建主题，也需要学习使用Java API来创建主题。\r\n\r\nKafka将zookeeper的操作封装成一个ZkUtils类，通过AdminUtils类来调用ZkUtils，来实现Kafka中元数据的操作。\r\n\r\n下面一个例子是使用AdminUtils来创建主题，并同时创建指定大小的分区数。\r\n\r\n    // 连接配置\r\n    private static final String ZK_CONNECT = \"10.0.90.53:2181\";\r\n\r\n    // session过期时间\r\n    private static final int SEESSION_TIMEOUT = 30 * 1000;\r\n\r\n    // 连接超时时间\r\n    private static final int CONNECT_TIMEOUT = 30 * 1000;\r\n\r\n    /**\r\n     * 创建主题\r\n     *\r\n     * @param topic 主题名称\r\n     * @param partition 分区数\r\n     * @param repilca 副本数\r\n     * @param properties 配置信息\r\n     */\r\n    public static void createTopic(String topic, int partition, int repilca, Properties properties) {\r\n        ZkUtils zkUtils = null;\r\n        try {\r\n            // 创建zkutil\r\n            zkUtils = ZkUtils.apply(ZK_CONNECT, SEESSION_TIMEOUT, CONNECT_TIMEOUT, JaasUtils.isZkSecurityEnabled());\r\n            if (!AdminUtils.topicExists(zkUtils, topic)) {\r\n                //主题不存在，则创建主题\r\n                AdminUtils.createTopic(zkUtils, topic, partition, repilca, properties, AdminUtils.createTopic$default$6());\r\n            }\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            zkUtils.close();\r\n        }\r\n    }\r\n\r\n\r\n\r\n执行该方法，创建主题，\r\n\r\n在centos7中查看之前创建的主题：\r\n\r\nbin/kafka-topics.sh --list --zookeeper localhost:2181  \r\n\r\n\r\n删除主题：\r\n\r\n/**\r\n * 删除主题\r\n *\r\n * @param topic\r\n */\r\npublic static void deleteTopic(String topic){\r\n    ZkUtils zkUtils = null;\r\n    try {\r\n        zkUtils = ZkUtils.apply(ZK_CONNECT, SEESSION_TIMEOUT, CONNECT_TIMEOUT, JaasUtils.isZkSecurityEnabled());\r\n        AdminUtils.deleteTopic(zkUtils,topic);\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n    } finally {\r\n        zkUtils.close();\r\n    }\r\n}\r\n\r\n\r\n生产者API\r\n在掌握了创建和删除主题之后，接下来，学习Kafka的生产者API。\r\n\r\nKafka中的生产者，通过KafkaProducer这个类来实现的，在介绍这个类的使用之前，首先介绍kafka的配置项，这也是实际生产中比较关心的。\r\n\r\n消息发送流程\r\n实例化生产者时，有三个配置是必须指定的：\r\n\r\nbootstrap.servers:配置连接代理列表，不必包含Kafka集群的所有代理地址，当连接上一个代理后，会从集群元数据信息中获取其他存活的代理信息。但为了保证能够成功连上Kafka集群，在多代理集群的情况下，建议至少配置两个代理。\r\n（由于电脑配置有限，本文实验的是单机情况）\r\nkey.serializer ： 用于序列化消息Key的类\r\nvalue.serializer ：用于序列化消息值（Value）的类\r\n向Kafka发送一个消息，基本上要经过以下的流程：\r\n\r\n1.配置Properties对象，这个是必须的\r\n\r\n2.实例化KafkaProducer对象\r\n\r\n3.实例化ProducerRecord对象，每条消息对应一个ProducerRecord对象\r\n\r\n4.调用KafkaProducer的send方法，发送消息。发送消息有两种，一种是带回调函数的（如果发送消息有异常，会在回调函数中返回），另一种是不带回调函数的。\r\n\r\nKafkaProducer默认是异步发送消息，首先它会将消息缓存到消息缓冲区中，当缓存区累积到一定数量时，将消息封装成一个\r\n\r\nRecordBatch，统一发送消息。也就是说，发送消息实质上分为两个阶段，第一将消息发送到消息缓冲区，第二执行网络I/O操作\r\n\r\n5.关闭KafkaProducer，释放连接的资源。\r\n\r\n了解以上的流程，那么接下来就实现Java版本的API。\r\n\r\n代码实例\r\n第一步：\r\n\r\n新建一个消息实体类，模拟支付订单消息，包含消息的ID，商家名称，创建时间，备注。\r\n\r\npublic class OrderMessage {\r\n\r\n    // 订单ID\r\n    private String id;\r\n\r\n    // 商家名称\r\n    private String sName;\r\n\r\n    // 创建时间\r\n    private long createTime;\r\n\r\n    // 备注\r\n    private String remake;\r\n\r\n    public String getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(String id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getsName() {\r\n        return sName;\r\n    }\r\n\r\n    public void setsName(String sName) {\r\n        this.sName = sName;\r\n    }\r\n\r\n    public long getCreateTime() {\r\n        return createTime;\r\n    }\r\n\r\n    public void setCreateTime(long createTime) {\r\n        this.createTime = createTime;\r\n    }\r\n\r\n    public String getRemake() {\r\n        return remake;\r\n    }\r\n\r\n    public void setRemake(String remake) {\r\n        this.remake = remake;\r\n    }\r\n\r\n    @Override\r\n    public String toString() {\r\n        return \"OrderMessage{\" +\r\n                \"id=\'\" + id + \'\\\'\' +\r\n                \", sName=\'\" + sName + \'\\\'\' +\r\n                \", createTime=\" + createTime +\r\n                \", remake=\'\" + remake + \'\\\'\' +\r\n                \'}\';\r\n    }\r\n}\r\n第二步：\r\n\r\n这里简单的发送一个消息demo，按照上面的流程，生产者例子如下：\r\n\r\npackage kafka.producer;\r\n\r\nimport kafka.OrderMessage;\r\nimport org.apache.kafka.clients.producer.KafkaProducer;\r\nimport org.apache.kafka.clients.producer.ProducerConfig;\r\nimport org.apache.kafka.clients.producer.ProducerRecord;\r\n\r\nimport java.util.Properties;\r\nimport java.util.UUID;\r\n\r\n/**\r\n * kafka生产者\r\n */\r\npublic class ProducerSimpleDemo {\r\n    static Properties properties = new Properties();\r\n\r\n    //主题名称\r\n    static String topic = \"myTopic\";\r\n\r\n    //生产者\r\n    static KafkaProducer<String, String> producer = null;\r\n\r\n    //生产者配置\r\n    static {\r\n        properties.put(org.apache.kafka.clients.producer.ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.0.90.53:9092\");\r\n        properties.put(org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringSerializer\");\r\n        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringSerializer\");\r\n        producer = new KafkaProducer<>(properties);\r\n    }\r\n\r\n    public static void main(String args[]) throws Exception {\r\n        sendMsg();\r\n    }\r\n\r\n    /**\r\n     * 发送消息\r\n     *\r\n     * @throws Exception\r\n     */\r\n    public static void sendMsg() throws Exception {\r\n        ProducerRecord<String, String> record = null;\r\n        try {\r\n            // 循环发送一百条消息\r\n            for (int i = 0; i < 10; i++) {\r\n                // 构造待发送的消息\r\n                OrderMessage orderMessage = new OrderMessage();\r\n                orderMessage.setId(UUID.randomUUID().toString());\r\n                long timestamp = System.nanoTime();\r\n                orderMessage.setCreateTime(timestamp);\r\n                orderMessage.setRemake(\"remind\");\r\n                orderMessage.setsName(\"test\");\r\n                // 实例化ProducerRecord\r\n                record = new ProducerRecord<String, String>(topic, timestamp + \"\", orderMessage.toString());\r\n                producer.send(record, (metadata, e) -> {\r\n                    // 使用回调函数\r\n                    if (null != e) {\r\n                        e.printStackTrace();\r\n                    }\r\n                    if (null != metadata) {\r\n                        System.out.println(String.format(\"offset: %s, partition:%s, topic:%s  timestamp:%s\", metadata.offset(), metadata.partition(), metadata.topic(), metadata.timestamp()));\r\n                    }\r\n                });\r\n            }\r\n\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            producer.close();\r\n        }\r\n    }\r\n}\r\n运行,结果就出现了，异常。\r\n\r\n异常记录：\r\n\r\n2018-07-30 18:05:10.755 DEBUG 10272 --- [ad | producer-1] o.apache.kafka.common.network.Selector   : Connection with localhost/127.0.0.1 disconnected\r\njava.net.ConnectException: Connection refused: no further information\r\nat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.8.0_111]\r\nat sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source) ~[na:1.8.0_111]\r\nat org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51) ~[kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:73) ~[kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:323) [kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.common.network.Selector.poll(Selector.java:291) [kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:260) [kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:236) [kafka-clients-0.10.1.1.jar:na]\r\nat org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:148) [kafka-clients-0.10.1.1.jar:na]\r\nat java.lang.Thread.run(Unknown Source) [na:1.8.0_111]\r\n\r\n可以看到报错第一句显示：Connection with localhost/127.0.0.1 disconnected\r\n但是可以看到自己的配置是正确的。\r\n\r\n这里需要在kafka中修改部分配置：\r\n在配置kafka中，首先需要修改kafka的配置server.properties中的\r\n\r\n advertised.listeners=PLAINTEXT://:your.host.name:9092\r\n翻译过来就是hostname和端口是用来建议给生产者和消费者使用的。\r\n如果没有设置，将会使用listeners的配置，如果listeners也没有配置，将使用java.net.InetAddress.getCanonicalHostName()来获取这个hostname和port，对于ipv4，基本就是localhost了。\r\n \r\n\"PLAINTEXT\"表示协议，可选的值有PLAINTEXT和SSL，hostname可以指定IP地址，也可以用\"0.0.0.0\"表示对所有的网络接口有效，如果hostname为空表示只对默认的网络接口有效\r\n也就是说如果你没有配置advertised.listeners，就使用listeners的配置通告给消息的生产者和消费者，这个过程是在生产者和消费者获取源数据(metadata)。\r\n\r\n修改之后：\r\nadvertised.listeners=PLAINTEXT://10.0.90.53:9092\r\n需要注意的是，如果Kafka有多个节点，那么需要每个节点都按照这个节点的实际hostname和port情况进行设置。\r\n\r\n修改完毕，重启Kafka服务，开启消费者，接受消息，在服务器中输入：\r\n\r\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic myTopic --from-beginning\r\n可以看到服务器中的消费者：\r\n\r\n\r\n\r\n\r\n成功接收到消息。之前提到过在生产者有回调函数，来看看回调函数的输出：\r\noffset: 0, partition:0, topic:myTopic  timestamp:1533199115840\r\noffset: 1, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 2, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 3, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 4, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 5, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 6, partition:0, topic:myTopic  timestamp:1533199115850\r\noffset: 7, partition:0, topic:myTopic  timestamp:1533199115852\r\noffset: 8, partition:0, topic:myTopic  timestamp:1533199115852\r\noffset: 9, partition:0, topic:myTopic  timestamp:1533199115852\r\n打印出了偏移值，分区，主题，和时间戳。说明发送成功了。到此就完成第一个Helloworld操作了。\r\n我们可以看到回调函数返回的消息，怎么都在一个分区中呢？下面来研究分区器。\r\n\r\n自定义分区器\r\nKafka在底层摒弃了Java堆缓存机制，采用了操作系统级别的页缓存，同时将随机写操作改为顺序写，再结合Zero-Copy的特性极大地改善了IO性能。\r\n\r\n这个在单机上的提高，对于集群，Kafka使用了分区，将topic的消息分散到多个分区上，并保存在不同的机器上。\r\n\r\n但是是否分区越多，效率越高呢？也不尽然！\r\n\r\n1.每个分区在底层文件系统都有属于自己的一个目录。该目录下通常会有两个文件： base_offset.log和base_offset.index。Kafak的controller和ReplicaManager会为每个broker都保存这两个文件句柄(file handler)。很明显，如果分区数越多，所需要保持打开状态的文件句柄数也就越多，最终可能会突破你的ulimit -n的限制。\r\n\r\n2.消费者和生产者都会为分区缓存消息，分区越多，缓存的消息就越多，占用的内存就越大。\r\n\r\n3.降低高可用，Kafka是通过高可用来实现高可用性的。我们知道在集群中往往会有一个leader，假设集群中有10个Kafka进程，1个leader，9个follwer，如果一个leader挂了，那么就会重新选出一个leader，如果集群中有10000个分区，那么将要花费很长的时间，这对于高可用是有损耗的。\r\n\r\n\r\n\r\n本身kafka有自己的分区策略的，如果未指定，就会使用默认的分区策略：\r\n\r\nKafka根据传递消息的key来进行分区的分配，即hash(key) % numPartitions。如果Key相同的话，那么就会分配到统一分区。\r\n\r\n\r\n\r\nKafka提供了自定义的分区器，只要实现Partitioner接口即可，下面是自定义分区的例子：\r\n\r\npackage kafka.partition;\r\n\r\nimport org.apache.kafka.clients.producer.Partitioner;\r\nimport org.apache.kafka.common.Cluster;\r\n\r\nimport java.util.Map;\r\n\r\n/\r\n * 自定义分区器\r\n */\r\npublic class PartitionUtil implements Partitioner {\r\n\r\n    // 分区数\r\n    private static final Integer PARTITION_NUM = 6;\r\n\r\n    @Override\r\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\r\n        if (null == key){\r\n            return 0;\r\n        }\r\n        String keyValue = String.valueOf(key);\r\n        // key取模\r\n        int partitionId = (int) (Long.valueOf(key.toString())%PARTITION_NUM);\r\n        return partitionId;\r\n    }\r\n\r\n    @Override\r\n    public void close() {\r\n\r\n    }\r\n\r\n    @Override\r\n    public void configure(Map<String, ?> configs) {\r\n\r\n    }\r\n}\r\n\r\n还是刚才分区的代码，只要在之前的配置中加上\r\nproperties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, PartitionUtil.class.getName());\r\n运行生产者，回调函数打印如下：\r\noffset: 3, partition:5, topic:MyOrder  timestamp:1533205894785\r\noffset: 5, partition:3, topic:MyOrder  timestamp:1533205893202\r\noffset: 6, partition:3, topic:MyOrder  timestamp:1533205894784\r\noffset: 2, partition:2, topic:MyOrder  timestamp:1533205894785\r\noffset: 4, partition:1, topic:MyOrder  timestamp:1533205894785\r\noffset: 5, partition:1, topic:MyOrder  timestamp:1533205894785\r\noffset: 5, partition:0, topic:MyOrder  timestamp:1533205894784\r\noffset: 6, partition:0, topic:MyOrder  timestamp:1533205894784\r\noffset: 7, partition:0, topic:MyOrder  timestamp:1533205894785\r\noffset: 8, partition:0, topic:MyOrder  timestamp:1533205894786\r\n分区成功了，在实际生产过程中，可以根据项目的实际需要进行分区设计。\r\n\r\n\r\n线程池生产者\r\n在实际生产过程中，通常消息数量是比较多的，就可以考虑使用线程池。\r\n\r\n使用线程池发送消息时，要考虑两点：1.需要结合实际情况，合理设计线程池的大小；2.使用线程池时，消息的发送是无序的，如果对消息的顺序有要求，不建议使用。\r\n\r\n如果使用线程池，建议是只实例化一个KafkaProducer对象，这样性能最好。代码如下：\r\n\r\n首先写一个线程类：\r\n\r\npackage kafka.producer;\r\n\r\nimport org.apache.kafka.clients.producer.KafkaProducer;\r\nimport org.apache.kafka.clients.producer.ProducerRecord;\r\n\r\n/\r\n * 生产者线程\r\n /\r\npublic class ProducerThread implements Runnable {\r\n\r\n    private KafkaProducer<String, String> producer = null;\r\n    private ProducerRecord<String, String> record = null;\r\n\r\n    public ProducerThread(KafkaProducer<String, String> producer, ProducerRecord<String, String> record) {\r\n        this.producer = producer;\r\n        this.record = record;\r\n    }\r\n\r\n    @Override\r\n    public void run() {\r\n        producer.send(record, (metadata, e) -> {\r\n            if (null != e) {\r\n                e.printStackTrace();\r\n            }\r\n            if (null != metadata) {\r\n                System.out.println(\"消息发送成功 ：         \"+String.format(\"offset: %s, partition:%s, topic:%s  timestamp:%s\",\r\n                        metadata.offset(), metadata.partition(), metadata.topic(), metadata.timestamp()));\r\n            }\r\n        });\r\n    }\r\n\r\n}\r\n\r\n\r\n\r\n接着完成启动类，启动类中自定义了一个线程池，这里还是有一些遐思，就是没有自定义，线程创建工厂，没有指定创建的线程名称，在实际生产中，最好是自定义线程工厂。\r\n\r\n代码如下：\r\n\r\npackage kafka.producer;\r\n\r\nimport kafka.OrderMessage;\r\nimport kafka.partition.PartitionUtil;\r\nimport org.apache.kafka.clients.producer.;\r\nimport org.apache.kafka.clients.producer.ProducerConfig;\r\n\r\nimport java.util.Properties;\r\nimport java.util.UUID;\r\nimport java.util.concurrent.;\r\n\r\n/**\r\n * 线程池生产者\r\n \r\n * @author tangj\r\n * @date 2018/7/29 20:15\r\n /\r\npublic class ProducerDemo {\r\n    static Properties properties = new Properties();\r\n\r\n    static String topic = \"MyOrder\";\r\n\r\n    static KafkaProducer<String, String> producer = null;\r\n\r\n    // 核心池大小\r\n    static int corePoolSize = 5;\r\n\r\n    // 最大值\r\n    static int maximumPoolSize = 20;\r\n\r\n    // 无任务时存活时间\r\n    static long keepAliveTime = 60;\r\n\r\n    // 时间单位\r\n    static TimeUnit timeUnit = TimeUnit.SECONDS;\r\n\r\n    // 阻塞队列\r\n    static BlockingQueue blockingQueue = new LinkedBlockingQueue();\r\n\r\n    // 线程池\r\n    static ExecutorService service = null;\r\n\r\n    static {\r\n        // 配置项\r\n        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"10.0.90.53:9092\");\r\n        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, PartitionUtil.class.getName());\r\n        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringSerializer\");\r\n        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringSerializer\");\r\n        producer = new KafkaProducer<>(properties);\r\n        // 初始化线程池\r\n        service = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, blockingQueue);\r\n    }\r\n\r\n    public static void main(String args[]) throws Exception {\r\n        for (int i = 0; i < 6; i++) {\r\n            service.submit(createMsgTask());\r\n        }\r\n    }\r\n\r\n\r\n    /**\r\n     * 生产消息\r\n     \r\n     * @return\r\n     */\r\n    public static ProducerThread createMsgTask() {\r\n        OrderMessage orderMessage = new OrderMessage();\r\n        orderMessage.setId(UUID.randomUUID().toString());\r\n        long timestamp = System.nanoTime();\r\n        orderMessage.setCreateTime(timestamp);\r\n        orderMessage.setRemake(\"rem\");\r\n        orderMessage.setsName(\"test\");\r\n        ProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, timestamp + \"\", orderMessage.toString());\r\n        ProducerThread task = new ProducerThread(producer, record);\r\n        return task;\r\n    }\r\n\r\n}', '1', 'post', 'publish', 'kafka', 'kafka', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('13', '玩转Kafka中的消费者', 'article13', '1546855157', '1546939088', '玩转Kafka中的消费者\r\n发布于 2018-08-03\r\n上一篇介绍了如何使用Kafka的生产者，这一篇将介绍在实际生产中如何合理地使用Kafka的消费者API。\r\n\r\nKafka中消费者API分为新版和旧版，本章只介绍新版，旧版的就不做介绍了。\r\n\r\n准备工作\r\nkafka版本：2.11-1.1.1\r\n\r\n操作系统：centos7\r\n\r\njava：jdk1.8\r\n\r\n有了以上这些条件就OK了，具体怎么安装和启动Kafka这里就不强调了，可以看上一篇文章。\r\n\r\n新建一个maven工程，需要的依赖如下：\r\n\r\n<dependency>  \r\n    <groupId>org.apache.kafkagroupId>  \r\n    <artifactId>kafka_2.11artifactId>  \r\n    <version>1.1.1version>  \r\ndependency>  \r\n<dependency>\r\n\r\n<groupId>org.apache.kafkagroupId>\r\n\r\n<artifactId>kafka-clientsartifactId>\r\n\r\n<version>1.1.1version>\r\n\r\ndependency>\r\n\r\n\r\n简单的消费者例子\r\nKafka中是封装了KafkaConsumer类，消息接受都是通过该类来进行的。与生产者一样，在实例化消费者之前都是要进行配置的。\r\n\r\n首先介绍这里面的配置：\r\nbootstrap.servers:配置连接代理列表，不必包含Kafka集群的所有代理地址，当连接上一个代理后，会从集群元数据信息中获取其他存活的代理信息。但为了保证能够成功连上Kafka集群，在多代理集群的情况下，建议至少配置两个代理。（由于电脑配置有限，本文实验的是单机情况）\r\nkey.deserializer ： 用于反序列化消息Key的类\r\nvalue.deserializer ：用于反序列化消息值（Value）的类\r\ngroup.id：指定消费者所在的组\r\nclient.id：指定客户端所在组的ID\r\nenable.auto.commit：设置是否自动提交。在没有指定消费偏移量提交方式时，默认是每隔1S发送一次\r\nauto.commit.interval.ms：自动提交偏移值的时间间\r\n订阅消息的流程分为以下：\r\n1.消费者参数配置\r\n\r\n2.实例化消费者\r\n\r\n3.订阅主题\r\n\r\n4.从Kafka中拉取消息\r\n\r\n按照这样的流程代码如下：\r\n\r\npackage kafka.consumer;  \r\n\r\nimport org.apache.kafka.clients.consumer.ConsumerRecord;  \r\nimport org.apache.kafka.clients.consumer.ConsumerRecords;  \r\nimport org.apache.kafka.clients.consumer.KafkaConsumer;  \r\n\r\nimport java.util.Arrays;  \r\nimport java.util.Properties;  \r\n\r\n/**  \r\n * 简单的消费者  \r\n  *  \r\n * @author tangj  \r\n */ public class KafkaSimpleDemo {  \r\n    static Properties properties = new Properties();  \r\n\r\n    private static String topic = \"MyOrder\";  \r\n\r\n    //poll超时时间  \r\n  private static long pollTimeout = 2000;  \r\n\r\n    // 1.消费者配置  \r\n  static {  \r\n        // bootstarp server 地址  \r\n  properties.put(\"bootstrap.servers\", \"10.0.90.53:9092\");  \r\n        // group.id指定消费者，所在的组  \r\n  properties.put(\"group.id\", \"order\");  \r\n        // 组中client 的ID名称  \r\n  properties.put(\"client.id\", \"consumer\");  \r\n\r\n        // 在没有指定消费偏移量提交方式时，默认是每个1s提交一次偏移量，可以通过auto.commit.interval.ms参数指定提交间隔  \r\n  // 自动提交要设置成true  \r\n // 手动提交设置成false  \r\n  properties.put(\"enable.auto.commit\", true);  \r\n        // 自动提交偏移值的 时间间隔  \r\n  properties.put(\"auto.commit.interval.ms\", 2000);  \r\n\r\n        // key序列化  \r\n  properties.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");  \r\n        // value序列化  \r\n  properties.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");  \r\n    }  \r\n\r\n    public static void main(String args[]) {  \r\n        consumeAutoCommit();  \r\n    }  \r\n\r\n    /**  \r\n * 消费消息自动提交偏移值  \r\n  */  \r\n  public static void consumeAutoCommit() {  \r\n        //2\\. 实例化消费者  \r\n  KafkaConsumer kafkaConsumer = new KafkaConsumer(properties);  \r\n        // 3.订阅主题  \r\n  kafkaConsumer.subscribe(Arrays.asList(topic));  \r\n\r\n        try {  \r\n            // 消费者是一个长期的过程，所以使用永久循环，  \r\n  while (true) {  \r\n                // 4.拉取消息  \r\n  ConsumerRecords records = kafkaConsumer.poll(pollTimeout);  \r\n                for (ConsumerRecord record : records) {  \r\n                    System.out.println(\"消息总数为： \" + records.count());  \r\n                    System.out.println(\"收到消息： \" + String.format(\"partition = %d, offset= %d, key=%s, value=%s%n\",  \r\n                            record.partition(), record.offset(), record.key(), record.value()));  \r\n                }  \r\n            }  \r\n        } catch (Exception e) {  \r\n            e.printStackTrace();  \r\n        } finally {  \r\n            kafkaConsumer.close();  \r\n        }  \r\n    }  \r\n}  \r\n\r\n看了简单的消费者模式，来看看消费者中的其他知识：消费模型，分区均衡，偏移量的提交，多线程消费者。\r\n消费模型\r\n可以看到在配置的时候，配置了消费者组这个变量。这里主要讲讲消费模型。消费模型主要分为两种：消费者组模型，发布订阅模型\r\n消费者组中有多个消费者，组内的消费者共享一个group.id，并且有一个单独的client.id。消费者组用来消费一个主题下的所有分区，但是每个分区只能由该组内的一个消费者消费，不会被重复消费。\r\n\r\n发布订阅模型就是所有的消费者都可以通过订阅来获取Kafka中的消息。\r\n\r\n分区再平衡\r\n介绍一种情况，消费者并不是越多越好的，当消费者大于分区数时，就会有部分消费者一直空闲着。\r\n分区再平衡，即：parition rebanlance。总的来说分区再平衡就是一个消费者原来消费的分区变成由其他消费者消费，它只发生在消费者组中。\r\n\r\n再均衡的作用就是为了保证消费者组的高可用和伸缩性，但是再均衡期间消费者会无法读取消息，有短暂的暂停时间。\r\n\r\n偏移量的处理\r\n偏移量的左右就是记录已经消费的消息。之前的一个简单的demo演示了自动提交的方式，接下来介绍手动提交。\r\n在实际生产中，消费者拉取到消息之后会进行一些业务处理，比如存到数据库，写入缓存，网络请求等，这些都会有失败的可能，所以要对偏移值进行更精细的控制。\r\n\r\n手动提交有两种方式：\r\n\r\n第一种是同步提交，同步提交是阻塞的，对于提交失败的处理，它会一直提交，直到提交成功。\r\n\r\n第二种是异步提交，异步提交是非阻塞的，对于提交失败，也不会重新提交。\r\n\r\n当然，对于手动提交的业务设计，还是要结合具体业务进行考虑和设计。手动提交之后，需要设置enable.auto.commit为false.并且不需要设置auto.commit.interval.ms。\r\n\r\n下面给出一个自动提交的例子，设置没消费5次，提交一次偏移值：\r\n\r\n\r\n\r\n\r\npublic static void consumeHandleCommit() {\r\n    KafkaConsumer<string, string=\"\"> kafkaConsumer = new KafkaConsumer<string, string=\"\">(properties);\r\n    try {\r\n        int maxcount = 5;\r\n        int count = 0;\r\n        kafkaConsumer.subscribe(Arrays.asList(topic));\r\n        for (; ; ) {\r\n            // 拉取消息\r\n  ConsumerRecords<string, string=\"\"> records = kafkaConsumer.poll(polltimeout);\r\n            for (ConsumerRecord<string, string=\"\"> record : records) {\r\n                System.out.println(\"收到消息： \" + String.format(\"partition = %d, offset= %d, key=%s, value=%s%n\",\r\n                        record.partition(), record.offset(), record.key(), record.value()));\r\n                count++;\r\n            }\r\n            // 业务逻辑完成后，提交偏移量\r\n  if (count >= maxcount) {\r\n                kafkaConsumer.commitAsync(new OffsetCommitCallback() {\r\n                    @Override\r\n  public void onComplete(Map<topicpartition, offsetandmetadata=\"\"> offsets, Exception exception) {\r\n                        if (null != exception) {\r\n                            exception.printStackTrace();\r\n                        } else {\r\n                            System.out.println(\"偏移值提交成功\");\r\n                        }\r\n                    }\r\n                });\r\n                count = 0;\r\n            }\r\n        }\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n    } finally {\r\n        kafkaConsumer.close();\r\n    }\r\n</topicpartition,></string,></string,></string,></string,>\r\n\r\n\r\n\r\n\r\n多线程消费者\r\n单线程的消费者效率肯定是低于多线程的消费者的，但是消费者的多线程设计与生产者不同，KafkaConsumer是非线程安全的。\r\n\r\n保证线程安全，每个线程，各自实例化一个KafkaConsumer对象，并且多个消费者线程只消费同一个主题，不考虑多个消费者线程消费同一个分区。\r\n\r\n线程实体类：\r\n\r\npackage kafka.consumer;\r\n\r\nimport org.apache.kafka.clients.consumer.ConsumerRecord;\r\nimport org.apache.kafka.clients.consumer.ConsumerRecords;\r\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\r\n\r\nimport java.util.Arrays;\r\nimport java.util.Map;\r\nimport java.util.Properties;\r\n\r\npublic class KafkaConsumerThread implements Runnable {\r\n\r\n    //每个线程私有一个consumer实例\r\n\r\n    private KafkaConsumer<String,String> consumer;\r\n\r\n    public KafkaConsumerThread(Map<String,Object> configMap,String topic) {\r\n        Properties properties = new Properties();\r\n        properties.putAll(configMap);\r\n        this.consumer = new KafkaConsumer<String, String>(properties);\r\n        consumer.subscribe(Arrays.asList(topic));\r\n    }\r\n\r\n    @Override\r\n    public void run() {\r\n\r\n        try {\r\n            for (; ; ) {\r\n                // 拉取消息\r\n                ConsumerRecords<String, String> records = consumer.poll(1000);\r\n                for (ConsumerRecord<String, String> record : records) {\r\n                    System.out.println(\"收到消息：          \" + String.format(\"partition = %d, offset= %d, key=%s, value=%s%n\",\r\n                            record.partition(), record.offset(), record.key(), record.value()));\r\n                }\r\n            }\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            consumer.close();\r\n        }\r\n    }\r\n}\r\n线程启动类：\r\n\r\npackage kafka.consumer;\r\n\r\nimport java.util.HashMap;\r\nimport java.util.Map;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\n\r\npublic class KafkaConsumerExcutor {\r\n\r\n\r\n    /**\r\n     * kafkaConsumer是非线程安全的，处理好多线程同步的方案是\r\n     * 每个线程实例化一个kafkaConsumer对象\r\n     */\r\n    public static void main(String args[]) {\r\n\r\n        String topic = \"hello\";\r\n\r\n        Map<String, Object> configMap = new HashMap<>();\r\n        configMap.put(\"bootstrap.servers\", \"10.0.90.53:9092\");\r\n        //group.id指定消费者，所在的组,保证所有线程都在一个消费者组\r\n        configMap.put(\"group.id\", \"test\");\r\n        configMap.put(\"enable.auto.commit\", true);\r\n        configMap.put(\"auto.commit.interval.ms\", 1000);\r\n\r\n        // key序列化\r\n        configMap.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\r\n        // value序列化\r\n        configMap.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\r\n\r\n        ExecutorService service = Executors.newFixedThreadPool(6);\r\n        // 该主题总共有6个分区，那么保证6个线程\r\n        for (int i = 0; i < 6; i++) {\r\n            service.submit(new KafkaConsumerThread(configMap, topic));\r\n        }\r\n    }\r\n}\r\n\r\n\r\n总结\r\n本文介绍了kafka中的消费者，包括多线程消费者，偏移量的处理，以及分区再平衡。\r\n\r\n切记一点，实际的生产中消费者需要根据实际业务来进行设计。', '1', 'post', 'publish', 'kafka', 'kafka', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('15', '有话说', 'about', '1547012883', '1547623065', '有话说\r\n发布于 2017-02-23\r\n站在巨人肩膀上：tale和MyBlog\r\n\r\n个人博客小站，也算是从无到有的过程\r\n\r\n本站使用springboot，mybatis，redis，maven\r\n\r\n这是我的博客园\r\n\r\n欢迎常来逛逛，(≖‿≖)✧，\r\n\r\n交流交流技术，最近从零开始学习大数据（买了本超厚的书），我的邮箱是jantent@foxmail.com\r\n\r\nalt', '1', 'page', 'publish', null, null, null, '0', '0', null, null, null);
INSERT INTO `t_contents` VALUES ('16', 'ZAB协议', 'article16', '1547108390', '1547109400', 'ZAB协议\r\n发布于 2018-09-28\r\nzab协议是zookeeper的核心内容，学好zab对于理解zookeeper是最基本的一环，本文主要介绍ZAB协议。\r\n\r\n主要内容\r\n所有事物请求必须由一个全局唯一的服务器来协调处理。这样的服务器成为Leader服务器，而余下的其他服务器则成为Follwer服务器。Leader服务器负责将一个客户端事物请求转换成一个事物Proposal(提议)，并将改Proposal分发给集群中所有的Follwer服务器。之后Leader需要等待所有Follower的反馈，一旦超过半数的Follower服务器进行了正确的反馈后，那么Leader就会再次向所有的Follower服务器分发Commit消息，要求其将前一个Propersal进行提交。\r\n\r\n协议介绍\r\nZAB协议两种基本的模式为崩溃恢复和消息广播。\r\n\r\n当整个服务框架在启动中，或者当Leader服务器出现网络中断、崩溃退出与重启等异常情况时，zab协议就会进入崩溃恢复模式并选举出新的Leader服务器。当选举产生了新的Leader服务器，同时集群中已经有过半的服务器与新的Leader服务器完成状态同步之后，ZAB协议就会退出崩溃恢复模式。\r\n\r\n其中，状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器数据状态保持一致。当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个集群就会进入消息广播模式了。\r\n\r\n当一台同样遵守ZAB协议的服务启动后加入到集群中时，如果集群中已经有一个Leader服务器在负责进行消息广播，那么新加入的服务器就会直接进入数据恢复模式（找到Leader所在的服务器，并与其进行数据同步）然后参与到消息广播中。因为ZAB协议中只允许唯一的一个Leader服务器来进行事务请求的处理。\r\n\r\nLeader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器首先会将这个事务请求转发给Leader服务器，由Leader服务器发起一轮广播。\r\n\r\n当Leader服务器出现崩溃退出或者机器重启，或者集群中已经不存在过半的服务器与该Leader服务器保持正常通讯时，那么重新开始新一轮的原子广播事务操作之前，所有集群中的进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态。于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。\r\n\r\n一个机器要成为新的Leader，必须获得过半的进程的支持，同时由于每个进程都有可能会崩溃，因此ZAB协议在运行期间，前后会出现多个Leader，并且一个进程可能会多次成为Leader。进入崩溃恢复模式后，只要集群中存在过半的服务器能够彼此进行正常通信，那么就可以产生一个新的Leader并在此进入消息广播模式。\r\n\r\n消息广播\r\n ZAB协议的消息广播过程使用的是一个原子广播协议，类似于一个二阶段提交过程，针对客户端的事务请求，Leader 服务器会为其生成对应的事务Proposal，并将其发送给集群中其他所有的服务器，然后再分别收集各自的选票，最后进行事务提交。如下如图所示：', '1', 'post', 'draft', 'zookeeper', 'zookeeper', '', '0', '0', '1', '1', '1');
INSERT INTO `t_contents` VALUES ('17', 'emoji符号大全', 'article17', '1547609384', '1547609452', 'emoji符号大全(如有符号显示不正常，请更换浏览器或操作系统浏览。)\r\n表情 人物 手势 日常 手机 公共 动物 植物 自然 饮食 文体 恐怖 旅游 物品 标志 生肖 星座 钟表 心形 花草 树叶 月亮 水果 钱币 交通 建筑 办公 箭头\r\n:rose::four_leaf_clover::apple::moneybag::iphone::crescent_moon::maple_leaf::fallen_leaf::leaves::tulip::gem::hocho::gun::basketball::soccer::zap::lips::+1::fire:\r\nemoji表情(非图片可复制)↑返回顶部\r\n:grinning::grin::joy::smiley::smile::sweat_smile::laughing::wink::blush::yum::sunglasses::heart_eyes::kissing_heart::kissing::kissing_smiling_eyes::kissing_closed_eyes::relaxed::innocent::neutral_face::expressionless::no_mouth::smirk::persevere::disappointed_relieved::open_mouth::hushed::sleepy::tired_face::sleeping::relieved::stuck_out_tongue::stuck_out_tongue_winking_eye::stuck_out_tongue_closed_eyes::unamused::sweat::pensive::confused::astonished::mask::confounded::disappointed::worried::triumph::cry::sob::frowning::anguished::fearful::grimacing::cold_sweat::scream::flushed::dizzy_face::rage::angry:\r\nemoji人物(非图片可复制)↑返回顶部\r\n:boy::girl::man::woman::older_man::older_woman::baby::person_with_blond_hair::cop::man_with_gua_pi_mao::man_with_turban::construction_worker::princess::guardsman::santa::bride_with_veil::angel::massage::haircut::person_frowning::person_with_pouting_face::no_good::ok_woman::information_desk_person::raising_hand::bow::raised_hands::pray::bust_in_silhouette::busts_in_silhouette::walking::runner::dancers::dancer::couple::two_men_holding_hands::two_women_holding_hands::couplekiss::couple_with_heart::family:\r\nemoji手势(非图片可复制)↑返回顶部\r\n:muscle::point_left::point_right::point_up::point_up_2::point_down::v::hand::ok_hand::+1::-1::fist::facepunch::wave::clap::open_hands::writing:\r\nemoji日常(非图片可复制)↑返回顶部\r\n:footprints::eyes::ear::nose::tongue::lips::kiss::eyeglasses::necktie::shirt::jeans::dress::kimono::bikini::womans_clothes::purse::handbag::pouch::school_satchel::briefcase::mans_shoe::athletic_shoe::high_heel::sandal::boot::crown::womans_hat::tophat::mortar_board::lipstick::nail_care::ring::closed_umbrella:\r\nemoji手机(非图片可复制)↑返回顶部\r\n:iphone::calling::signal_strength::vibration_mode::mobile_phone_off::phone::telephone_receiver::pager::fax:\r\nemoji公共(非图片可复制)↑返回顶部\r\n:recycle::atm::put_litter_in_its_place::potable_water::wheelchair::mens::womens::restroom::baby_symbol::wc::warning::children_crossing::no_entry::no_entry_sign::no_bicycles::no_smoking::do_not_litter::non-potable_water::no_pedestrians::underage::barber:\r\nemoji动物(非图片可复制)↑返回顶部\r\n:see_no_evil::hear_no_evil::speak_no_evil::monkey_face::monkey::dog::dog2::poodle::wolf::cat::smiley_cat::smile_cat::joy_cat::heart_eyes_cat::smirk_cat::kissing_cat::scream_cat::crying_cat_face::pouting_cat::cat2::tiger::tiger2::leopard::horse::racehorse::cow::ox::water_buffalo::cow2::pig::pig2::boar::pig_nose::ram::sheep::goat::dromedary_camel::camel::elephant::mouse::mouse2::rat::hamster::rabbit::rabbit2::bear::koala::panda_face::feet::chicken::rooster::hatching_chick::baby_chick::hatched_chick::bird::penguin::frog::crocodile::turtle::snake::dragon_face::dragon::whale::whale2::dolphin::fish::tropical_fish::blowfish::octopus::shell::snail::bug::ant::bee::beetle::butterfly:\r\nemoji植物(非图片可复制)↑返回顶部\r\n:bouquet::cherry_blossom::white_flower::rose::hibiscus::sunflower::blossom::tulip::seedling::evergreen_tree::deciduous_tree::palm_tree::cactus::ear_of_rice::herb::four_leaf_clover::maple_leaf::fallen_leaf::leaves:\r\nemoji自然(非图片可复制)↑返回顶部\r\n:earth_africa::earth_americas::earth_asia::globe_with_meridians::new_moon::waxing_crescent_moon::first_quarter_moon::moon::full_moon::waning_gibbous_moon::last_quarter_moon::waning_crescent_moon::crescent_moon::new_moon_with_face::first_quarter_moon_with_face::last_quarter_moon_with_face::sunny::full_moon_with_face::sun_with_face::star::star2::stars::cloud::partly_sunny::umbrella::zap::snowflake::fire::droplet::ocean:\r\nemoji饮食(非图片可复制)↑返回顶部\r\n:grapes::melon::watermelon::tangerine::lemon::banana::pineapple::apple::green_apple::pear::peach::cherries::strawberry::tomato::eggplant::corn::mushroom::chestnut::bread::meat_on_bone::poultry_leg::hamburger::fries::pizza::egg::stew::bento::rice_cracker::rice_ball::rice::curry::ramen::spaghetti::sweet_potato::oden::sushi::fried_shrimp::fish_cake::dango::icecream::shaved_ice::ice_cream::doughnut::cookie::birthday::cake::chocolate_bar::candy::lollipop::custard::honey_pot::baby_bottle::coffee::tea::sake::wine_glass::cocktail::tropical_drink::beer::beers::fork_and_knife:\r\nemoji文体(非图片可复制)↑返回顶部\r\n:circus_tent::performing_arts::art::slot_machine::rowboat::bath::ticket::trophy::soccer::baseball::basketball::football::rugby_football::tennis::8ball::bowling::golf::fishing_pole_and_fish::running_shirt_with_sash::ski::snowboarder::surfer::horse_racing::swimmer::bicyclist::mountain_bicyclist::dart::video_game::game_die::saxophone::guitar::trumpet::violin::clapper:\r\nemoji恐怖(非图片可复制)↑返回顶部\r\n:smiling_imp::imp::japanese_ogre::japanese_goblin::skull::skull_crossbones::ghost::alien::space_invader::bomb:\r\nemoji旅游(非图片可复制)↑返回顶部\r\n:volcano::mount_fuji::house::house_with_garden::office::post_office::european_post_office::hospital::bank::hotel::love_hotel::convenience_store::school::department_store::factory::japanese_castle::european_castle::wedding::tokyo_tower::statue_of_liberty::church::fountain::foggy::night_with_stars::city_sunset::city_sunrise::bridge_at_night::milky_way::carousel_horse::ferris_wheel::roller_coaster::steam_locomotive::railway_car::bullettrain_side::bullettrain_front::train2::metro::light_rail::station::tram::monorail::mountain_railway::train::bus::oncoming_bus::trolleybus::busstop::minibus::ambulance::fire_engine::police_car::oncoming_police_car::taxi::oncoming_taxi::car::oncoming_automobile::truck::articulated_lorry::tractor::bike::fuelpump::rotating_light::traffic_light::vertical_traffic_light::construction::anchor::boat::speedboat::ship::airplane::seat::helicopter::suspension_railway::mountain_cableway::aerial_tramway::rocket::rice_scene::moyai::passport_control::customs::baggage_claim::left_luggage:\r\nemoji物品(非图片可复制)↑返回顶部\r\n:love_letter::gem::hocho::barber::door::toilet::shower::bathtub::hourglass::hourglass_flowing_sand::watch::alarm_clock::balloon::tada::confetti_ball::dolls::flags::wind_chime::ribbon::gift::postal_horn::radio::iphone::calling::phone::telephone_receiver::pager::fax::battery::electric_plug::computer::minidisc::floppy_disk::cd::dvd::movie_camera::tv::camera::video_camera::vhs::mag::mag_right::microscope::telescope::satellite::bulb::flashlight::izakaya_lantern::notebook_with_decorative_cover::closed_book::book::green_book::blue_book::orange_book::books::notebook::page_with_curl::scroll::page_facing_up::newspaper::bookmark_tabs::bookmark::moneybag::yen::dollar::euro::pound::money_with_wings::credit_card::email::e-mail::incoming_envelope::envelope_with_arrow::outbox_tray::inbox_tray::package::mailbox::mailbox_closed::mailbox_with_mail::mailbox_with_no_mail::postbox::pencil2::black_nib::memo::file_folder::open_file_folder::date::calendar::card_index::chart_with_upwards_trend::chart_with_downwards_trend::bar_chart::clipboard::pushpin::round_pushpin::paperclip::straight_ruler::triangular_ruler::scissors::lock::unlock::lock_with_ink_pen::closed_lock_with_key::key::hammer::gun::wrench::nut_and_bolt::link::syringe::pill::smoking::crystal_ball::triangular_flag_on_post::crossed_flags::sweat_drops::dash:\r\nemoji标志(非图片可复制)↑返回顶部\r\n:spades::hearts::diamonds::clubs::mahjong::flower_playing_cards::mute::speaker::sound::loud_sound::loudspeaker::mega::zzz::anger::speech_balloon::thought_balloon::hotsprings::cyclone::bell::no_bell::star_of_david::latin_cross::six_pointed_star::name_badge::beginner::trident::o::white_check_mark::ballot_box_with_check::heavy_check_mark::heavy_multiplication_x::x::negative_squared_cross_mark::heavy_plus_sign::heavy_minus_sign::heavy_division_sign::curly_loop::loop::part_alternation_mark::eight_spoked_asterisk::eight_pointed_black_star::sparkle::bangbang::interrobang::question::grey_question::grey_exclamation::exclamation::copyright::registered::tm::cinema::low_brightness::high_brightness::100::capital_abcd::abcd::1234::symbols::abc::a::ab::b::cl::cool::free::information_source::id::m::new::squared_ng::o2::ok::parking::sos::up::vs::koko::sa::u6708::u6709::u6307::ideograph_advantage::u5272::u7121::u7981::accept::u7533::u5408::u7a7a::congratulations::secret::u55b6::u6e80::black_small_square::white_small_square::white_medium_square::black_medium_square::white_medium_small_square::black_medium_small_square::black_large_square::white_large_square::large_orange_diamond::large_blue_diamond::small_orange_diamond::small_blue_diamond::small_red_triangle::small_red_triangle_down::diamond_shape_with_a_dot_inside::black_square_button::white_square_button::white_circle::black_circle::red_circle::large_blue_circle:\r\nemoji生肖(非图片可复制)↑返回顶部\r\n:mouse2::ox::tiger2::rabbit2::dragon::snake::racehorse::goat::monkey::rooster::dog2::pig2:\r\nemoji星座(非图片可复制)↑返回顶部\r\n:aries::taurus::gemini::cancer::leo::virgo::libra::scorpius::sagittarius::capricorn::aquarius::pisces::ophiuchus:\r\nemoji钟表(非图片可复制)↑返回顶部\r\n:clock12::clock1230::clock1::clock130::clock2::clock230::clock3::clock330::clock4::clock430::clock5::clock530::clock6::clock630::clock7::clock730::clock8::clock830::clock9::clock930::clock10::clock1030::clock11::clock1130::hourglass::hourglass_flowing_sand::watch::alarm_clock::stopwatch::timer_clock::mantelpiece_clock:\r\nemoji心形(非图片可复制)↑返回顶部\r\n:cupid::heart::heartbeat::broken_heart::two_hearts::sparkling_heart::heartpulse::blue_heart::green_heart::yellow_heart::purple_heart::gift_heart::revolving_hearts::heart_decoration::exclamation_heart:\r\nemoji花草(非图片可复制)↑返回顶部\r\n:bouquet::cherry_blossom::white_flower::rose::hibiscus::sunflower::blossom::tulip::seedling::herb::four_leaf_clover:\r\nemoji树叶(非图片可复制)↑返回顶部\r\n:herb::four_leaf_clover::maple_leaf::fallen_leaf::leaves:\r\nemoji月亮(非图片可复制)↑返回顶部\r\n:new_moon::waxing_crescent_moon::first_quarter_moon::moon::full_moon::waning_gibbous_moon::last_quarter_moon::waning_crescent_moon::crescent_moon::new_moon_with_face::first_quarter_moon_with_face::last_quarter_moon_with_face::full_moon_with_face:\r\nemoji水果(非图片可复制)↑返回顶部\r\n:grapes::melon::watermelon::tangerine::lemon::banana::pineapple::apple::green_apple::pear::peach::cherries::strawberry:\r\nemoji钱币(非图片可复制)↑返回顶部\r\n:yen::dollar::euro::pound::moneybag::money_with_wings::credit_card:\r\nemoji交通(非图片可复制)↑返回顶部\r\n:steam_locomotive::railway_car::bullettrain_side::bullettrain_front::train2::metro::light_rail::station::tram::monorail::mountain_railway::train::bus::oncoming_bus::trolleybus::busstop::minibus::ambulance::fire_engine::police_car::oncoming_police_car::taxi::oncoming_taxi::car::oncoming_automobile::truck::articulated_lorry::tractor::bike::fuelpump::rotating_light::traffic_light::vertical_traffic_light::construction::anchor::boat::rowboat::speedboat::ship::airplane::seat::helicopter::suspension_railway::mountain_cableway::aerial_tramway::rocket:\r\nemoji建筑(非图片可复制)↑返回顶部\r\n:house::house_with_garden::office::post_office::european_post_office::hospital::bank::hotel::love_hotel::convenience_store::school::department_store::factory::japanese_castle::european_castle::wedding::tokyo_tower::statue_of_liberty::church::city_sunset::city_sunrise::bridge_at_night:\r\nemoji办公(非图片可复制)↑返回顶部\r\n:iphone::calling::phone::telephone_receiver::pager::fax::battery::electric_plug::computer::minidisc::floppy_disk::cd::dvd::movie_camera::tv::camera::video_camera::vhs::mag::mag_right::microscope::telescope::satellite::notebook_with_decorative_cover::closed_book::book::green_book::blue_book::orange_book::books::notebook::page_with_curl::scroll::page_facing_up::newspaper::bookmark_tabs::bookmark::credit_card::email::e-mail::incoming_envelope::envelope_with_arrow::outbox_tray::inbox_tray::package::mailbox::mailbox_closed::mailbox_with_mail::mailbox_with_no_mail::postbox::pencil2::black_nib::memo::file_folder::open_file_folder::date::calendar::card_index::chart_with_upwards_trend::chart_with_downwards_trend::bar_chart::clipboard::pushpin::round_pushpin::paperclip::straight_ruler::triangular_ruler::scissors::lock::unlock::lock_with_ink_pen::closed_lock_with_key::key:\r\nemoji箭头(非图片可复制)↑返回顶部\r\n:arrow_up::arrow_upper_right::arrow_right::arrow_lower_right::arrow_down::arrow_lower_left::arrow_left::arrow_upper_left::arrow_up_down::left_right_arrow::leftwards_arrow_with_hook::arrow_right_hook::arrow_heading_up::arrow_heading_down::arrows_clockwise::arrows_counterclockwise::back::end::on::soon::top:', '1', 'post', 'publish', 'emoji', 'emoji', '', '0', '0', '1', '1', '1');

-- ----------------------------
-- Table structure for t_logs
-- ----------------------------
DROP TABLE IF EXISTS `t_logs`;
CREATE TABLE `t_logs` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `action` varchar(100) DEFAULT NULL,
  `data` varchar(2000) DEFAULT NULL,
  `author_id` int(10) DEFAULT NULL,
  `ip` varchar(20) DEFAULT NULL,
  `created` int(10) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_logs
-- ----------------------------

-- ----------------------------
-- Table structure for t_metas
-- ----------------------------
DROP TABLE IF EXISTS `t_metas`;
CREATE TABLE `t_metas` (
  `mid` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(200) DEFAULT NULL,
  `slug` varchar(200) DEFAULT NULL,
  `type` varchar(32) NOT NULL DEFAULT '',
  `description` varchar(200) DEFAULT NULL,
  `sort` int(10) unsigned DEFAULT '0',
  `parent` int(10) unsigned DEFAULT '0',
  PRIMARY KEY (`mid`),
  KEY `slug` (`slug`)
) ENGINE=InnoDB AUTO_INCREMENT=20 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_metas
-- ----------------------------
INSERT INTO `t_metas` VALUES ('1', 'springboot', null, 'category', null, '0', '0');
INSERT INTO `t_metas` VALUES ('2', '计算机网络', null, 'category', null, '0', '0');
INSERT INTO `t_metas` VALUES ('3', 'kafka', null, 'category', null, '0', '0');
INSERT INTO `t_metas` VALUES ('4', 'zookeeper', null, 'category', null, '0', '0');
INSERT INTO `t_metas` VALUES ('9', 'zookeeper', 'zookeeper', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('10', 'kafka', 'kafka', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('11', '计算机网络', '计算机网络', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('12', 'springboot', 'springboot', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('13', 'CSDN-专业IT技术社区', 'https://www.csdn.net/', 'link', '', '0', '0');
INSERT INTO `t_metas` VALUES ('14', 'mybatis', 'mybatis', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('15', 'thymeleaf', 'thymeleaf', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('16', 'redis', 'redis', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('17', 'netty', 'netty', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('18', 'emoji', 'emoji', 'tag', null, '0', '0');
INSERT INTO `t_metas` VALUES ('19', 'emoji', null, 'category', null, '0', '0');

-- ----------------------------
-- Table structure for t_options
-- ----------------------------
DROP TABLE IF EXISTS `t_options`;
CREATE TABLE `t_options` (
  `name` varchar(32) NOT NULL DEFAULT '',
  `value` varchar(1000) DEFAULT '',
  `description` varchar(200) DEFAULT NULL,
  PRIMARY KEY (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_options
-- ----------------------------
INSERT INTO `t_options` VALUES ('site_block_ips', '192.168.2.27,192.168.100.12', '黑名单IP列表');
INSERT INTO `t_options` VALUES ('site_description', 'springboot学习共享平台', null);
INSERT INTO `t_options` VALUES ('site_record', 'caolihui.com', null);
INSERT INTO `t_options` VALUES ('site_theme', 'jantent', '默认主题');
INSERT INTO `t_options` VALUES ('site_title', 'www.sharedblog.com', '共享博客');

-- ----------------------------
-- Table structure for t_relationships
-- ----------------------------
DROP TABLE IF EXISTS `t_relationships`;
CREATE TABLE `t_relationships` (
  `cid` int(10) unsigned NOT NULL,
  `mid` int(10) unsigned NOT NULL,
  PRIMARY KEY (`cid`,`mid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_relationships
-- ----------------------------
INSERT INTO `t_relationships` VALUES ('1', '1');
INSERT INTO `t_relationships` VALUES ('1', '12');
INSERT INTO `t_relationships` VALUES ('2', '1');
INSERT INTO `t_relationships` VALUES ('2', '12');
INSERT INTO `t_relationships` VALUES ('3', '1');
INSERT INTO `t_relationships` VALUES ('3', '12');
INSERT INTO `t_relationships` VALUES ('3', '17');
INSERT INTO `t_relationships` VALUES ('4', '1');
INSERT INTO `t_relationships` VALUES ('4', '12');
INSERT INTO `t_relationships` VALUES ('4', '16');
INSERT INTO `t_relationships` VALUES ('5', '1');
INSERT INTO `t_relationships` VALUES ('5', '12');
INSERT INTO `t_relationships` VALUES ('6', '1');
INSERT INTO `t_relationships` VALUES ('6', '12');
INSERT INTO `t_relationships` VALUES ('7', '1');
INSERT INTO `t_relationships` VALUES ('7', '12');
INSERT INTO `t_relationships` VALUES ('7', '15');
INSERT INTO `t_relationships` VALUES ('8', '1');
INSERT INTO `t_relationships` VALUES ('8', '12');
INSERT INTO `t_relationships` VALUES ('9', '1');
INSERT INTO `t_relationships` VALUES ('9', '12');
INSERT INTO `t_relationships` VALUES ('9', '14');
INSERT INTO `t_relationships` VALUES ('10', '2');
INSERT INTO `t_relationships` VALUES ('10', '11');
INSERT INTO `t_relationships` VALUES ('11', '3');
INSERT INTO `t_relationships` VALUES ('11', '10');
INSERT INTO `t_relationships` VALUES ('12', '3');
INSERT INTO `t_relationships` VALUES ('12', '10');
INSERT INTO `t_relationships` VALUES ('13', '3');
INSERT INTO `t_relationships` VALUES ('13', '10');
INSERT INTO `t_relationships` VALUES ('16', '4');
INSERT INTO `t_relationships` VALUES ('16', '9');
INSERT INTO `t_relationships` VALUES ('17', '18');
INSERT INTO `t_relationships` VALUES ('17', '19');

-- ----------------------------
-- Table structure for t_users
-- ----------------------------
DROP TABLE IF EXISTS `t_users`;
CREATE TABLE `t_users` (
  `uid` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `username` varchar(32) DEFAULT NULL,
  `password` varchar(64) DEFAULT NULL,
  `email` varchar(200) DEFAULT NULL,
  `home_url` varchar(200) DEFAULT NULL,
  `screen_name` varchar(32) DEFAULT NULL,
  `created` int(10) unsigned DEFAULT '0',
  `activated` int(10) unsigned DEFAULT '0',
  `logged` int(10) unsigned DEFAULT '0',
  `group_name` varchar(16) DEFAULT 'visitor',
  PRIMARY KEY (`uid`),
  UNIQUE KEY `name` (`username`),
  UNIQUE KEY `mail` (`email`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of t_users
-- ----------------------------
INSERT INTO `t_users` VALUES ('1', 'admin', 'a66abb5684c45962d887564f08346e8d', '972152412@qq.com', null, 'caolihui', '1490756162', '0', '0', 'visitor');
